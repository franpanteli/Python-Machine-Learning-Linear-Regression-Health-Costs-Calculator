{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9TX15KOkPBV"
      },
      "source": [
        "# Python-Machine-Learning-Linear-Regression-Health-Costs-Calculator\n",
        "# Author: Fran Panteli\n",
        "# 1. Contents  \n",
        "* **1. Contents**  \n",
        "* **2. Task Description**\n",
        "* **3. Importing the Data & Modules**\n",
        "* **4. Exploring the Healthcare Dataset**\n",
        "* **5. Preprocessing Data for Training the Machine Learning Model**\n",
        "* **6. Initialise the Architecture to Train the Model**\n",
        "* **7. Training the Model Using a Linear Regression Approach**\n",
        "* **8. Running Unit Tests for the Model in Python**\n",
        "\n",
        "# 2. Task Description\n",
        "*Note: You are currently reading this using Google Colaboratory which is a cloud-hosted version of Jupyter Notebook. This is a document containing both text cells for documentation and runnable code cells. If you are unfamiliar with Jupyter Notebook, watch this 3-minute introduction before starting this challenge: https://www.youtube.com/watch?v=inN8seMm7UI*\n",
        "\n",
        "---\n",
        "\n",
        "In this challenge, you will predict healthcare costs using a regression algorithm.\n",
        "\n",
        "You are given a dataset that contains information about different people including their healthcare costs. Use the data to predict healthcare costs based on new data.\n",
        "\n",
        "The first two cells of this notebook import libraries and the data.\n",
        "\n",
        "Make sure to convert categorical data to numbers. Use 80% of the data as the `train_dataset` and 20% of the data as the `test_dataset`.\n",
        "\n",
        "`pop` off the \"expenses\" column from these datasets to create new datasets called `train_labels` and `test_labels`. Use these labels when training your model.\n",
        "\n",
        "Create a model and train it with the `train_dataset`. Run the final cell in this notebook to check your model. The final cell will use the unseen `test_dataset` to check how well the model generalizes.\n",
        "\n",
        "To pass the challenge, `model.evaluate` must return a Mean Absolute Error of under 3500. This means it predicts health care costs correctly within $3500.\n",
        "\n",
        "The final cell will also predict expenses using the `test_dataset` and graph the results."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # 3. Importing the Data & Modules"
      ],
      "metadata": {
        "id": "KAABQ96puFnX"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rRo8oNqZ-Rj"
      },
      "source": [
        "#IMPORTING MODULES\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
        "\n",
        "\"\"\"\n",
        "-> The text in the markdown cell above explains the project task\n",
        "\t-> There are notes on this in the GitHub repository for this project\n",
        "-> The code in this cell imports the modules for the project\n",
        "\t-> We are importing matplotlib, numpy, pandas and TensorFlow\n",
        "\"\"\"\n",
        "\n",
        "# Import libraries. You may or may not use all of these.\n",
        "!pip install -q git+https://github.com/tensorflow/docs\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import tensorflow_docs as tfdocs\n",
        "import tensorflow_docs.plots\n",
        "import tensorflow_docs.modeling"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiX2FI4gZtTt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "2424aecc-3193-49ff-cda0-0fd793a56077"
      },
      "source": [
        "#IMPORTING DATA\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
        "\n",
        "\"\"\"\n",
        "\t-> The previous cell imported the modules for the project\n",
        "\t-> This cell imports the dataset for the project\n",
        "\t-> This sends an HTTP call to freeCodeCamp to import the healthcare dataset, unzips it and stores a CSV (spreadsheet file) of it in the variable called dataset\n",
        "\t-> We are printing out the tail of this dataset to show the format of the data which we are working with\n",
        "\t-> We now have the healthcare data:\n",
        "\t\t-> The demographics of patients and the cost of their healthcare\n",
        "\t\t-> This is stored in the variable called dataset\n",
        "\t\t-> We are going to first clean this data, and then train the linear regression model on it to make predictions\n",
        "\"\"\"\n",
        "\n",
        "!wget https://cdn.freecodecamp.org/project-data/health-costs/insurance.csv\n",
        "dataset = pd.read_csv('insurance.csv')\n",
        "dataset.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-20 09:11:16--  https://cdn.freecodecamp.org/project-data/health-costs/insurance.csv\n",
            "Resolving cdn.freecodecamp.org (cdn.freecodecamp.org)... 104.26.3.33, 172.67.70.149, 104.26.2.33, ...\n",
            "Connecting to cdn.freecodecamp.org (cdn.freecodecamp.org)|104.26.3.33|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 50264 (49K) [text/csv]\n",
            "Saving to: ‘insurance.csv.1’\n",
            "\n",
            "\rinsurance.csv.1       0%[                    ]       0  --.-KB/s               \rinsurance.csv.1     100%[===================>]  49.09K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-01-20 09:11:16 (103 MB/s) - ‘insurance.csv.1’ saved [50264/50264]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a225a73b-a49b-4260-88c0-477368b16ffc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>expenses</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1333</th>\n",
              "      <td>50</td>\n",
              "      <td>male</td>\n",
              "      <td>31.0</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>10600.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1334</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>31.9</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northeast</td>\n",
              "      <td>2205.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1335</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>36.9</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1629.83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1336</th>\n",
              "      <td>21</td>\n",
              "      <td>female</td>\n",
              "      <td>25.8</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southwest</td>\n",
              "      <td>2007.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1337</th>\n",
              "      <td>61</td>\n",
              "      <td>female</td>\n",
              "      <td>29.1</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>northwest</td>\n",
              "      <td>29141.36</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a225a73b-a49b-4260-88c0-477368b16ffc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a225a73b-a49b-4260-88c0-477368b16ffc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a225a73b-a49b-4260-88c0-477368b16ffc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      age     sex   bmi  children smoker     region  expenses\n",
              "1333   50    male  31.0         3     no  northwest  10600.55\n",
              "1334   18  female  31.9         0     no  northeast   2205.98\n",
              "1335   18  female  36.9         0     no  southeast   1629.83\n",
              "1336   21  female  25.8         0     no  southwest   2007.95\n",
              "1337   61  female  29.1         0    yes  northwest  29141.36"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Exploring the Healthcare Dataset"
      ],
      "metadata": {
        "id": "OufDIaCWuqFu"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcopvQh3X-kX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "5a11544c-242a-4d0e-b1af-3872152f2c91"
      },
      "source": [
        "\"\"\"\n",
        "\t-> Our dataset is stored in the variable called `dataset`\n",
        "\t-> We are using the `describe` method to print summary statistics for these data\n",
        "\t-> This dataset contains healthcare information about the age, BMI, number of children and expenses of US patients\n",
        "\t-> We are printing out summary statistics for the dataset in this cell\n",
        "\"\"\"\n",
        "\n",
        "# Exploratory analysis\n",
        "dataset.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ad0c7374-cab3-4b9a-9eab-cfa48881424b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>expenses</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1338.000000</td>\n",
              "      <td>1338.000000</td>\n",
              "      <td>1338.000000</td>\n",
              "      <td>1338.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>39.207025</td>\n",
              "      <td>30.665471</td>\n",
              "      <td>1.094918</td>\n",
              "      <td>13270.422414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>14.049960</td>\n",
              "      <td>6.098382</td>\n",
              "      <td>1.205493</td>\n",
              "      <td>12110.011240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>18.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1121.870000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>27.000000</td>\n",
              "      <td>26.300000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4740.287500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>39.000000</td>\n",
              "      <td>30.400000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>9382.030000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>51.000000</td>\n",
              "      <td>34.700000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>16639.915000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>64.000000</td>\n",
              "      <td>53.100000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>63770.430000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad0c7374-cab3-4b9a-9eab-cfa48881424b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ad0c7374-cab3-4b9a-9eab-cfa48881424b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ad0c7374-cab3-4b9a-9eab-cfa48881424b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "               age          bmi     children      expenses\n",
              "count  1338.000000  1338.000000  1338.000000   1338.000000\n",
              "mean     39.207025    30.665471     1.094918  13270.422414\n",
              "std      14.049960     6.098382     1.205493  12110.011240\n",
              "min      18.000000    16.000000     0.000000   1121.870000\n",
              "25%      27.000000    26.300000     0.000000   4740.287500\n",
              "50%      39.000000    30.400000     1.000000   9382.030000\n",
              "75%      51.000000    34.700000     2.000000  16639.915000\n",
              "max      64.000000    53.100000     5.000000  63770.430000"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\tFrom the previous cells:\n",
        "\t\t-> We have the healthcare costs of the patients <- this is the variable which we want our model to predict\n",
        "\t\t-> We also have three other variables, which are the age, BMI and number of children of each of the patients\n",
        "\t\t-> The dataset is also stored in the variable called `dataset`\n",
        "\n",
        "\tGenerating subplots with Python:\n",
        "\t\t-> In this cell, we are exploring the data by generating three subplots\n",
        "\t\t-> Since we are making a model which predicts the healthcare expenses of customers based off of their demographics, we are creating a 1x3 matrix of subplots which looks at three of those demographic characteristics from the datasets and plots the average healthcare expenses for each of them with a bar chart\n",
        "\t\t-> So we are initialising a 1x3 matrix of subplots with matplotlib -> this is done in the fist line of code in this cell\n",
        "\t\t-> We are plotting categorical data ('male' or 'female' is a string, for example)\n",
        "\t\t-> The second line of code in this is telling it which data we are using to create the bar charts of -> i.e the categorical consumer data which we know in relation to their expenses\n",
        "\t\t\t-> We are selecting this data because its type is 'object'\n",
        "\t\t\t-> We store these data in the variable called cols\n",
        "\t\t\t\t-> Since these are the customer demographic data, we want to plot the mean healthcare expenses for\n",
        "\t\t-> We are then iterating through this list of different columns and creating these plots for each\n",
        "\t\t-> The mean of the expenses for each group is on the y -> this is set up so that we are iterating through and creating bar plots of the mean of the expense with that category\n",
        "\n",
        "\tFrom this, we can see:\n",
        "\t\t-> Male-bodied people in this dataset spend more money on healthcare than did female-bodied people\n",
        "\t\t-> The healthcare expenses of smokers was significantly higher for smokers than non-smokers on average\n",
        "\t\t-> Healthcare expenses varied by geographic region, with patients in the South-East having the highest mean healthcare expenses and those in the North-West having the minimum mean expenditure\n",
        "\"\"\"\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
        "cols = [f for f in dataset.columns if dataset[f].dtype == 'object']\n",
        "for i, feature in enumerate(cols):\n",
        "    dataset[[feature,'expenses']].groupby(feature).mean().plot(kind='bar',ax=axes[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "b8VzpHk6lnXb",
        "outputId": "179da8af-e43c-48b6-c793-6f04b7e55891"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x288 with 3 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\tThis cell repeats the code in the last cell, but deals with numerical data:\n",
        "\t\t-> The previous cell plotted the categorical data in our dataset\n",
        "\t\t-> This was data which could be stored in a string (for example, if the patient was `female` or `male`)\n",
        "\t\t-> All of the data which we are investigating for trends in the dataset is an attribute of a patient (to do with their demographic), combined with the healthcare expenses of those patients\n",
        "\t\t-> The code in the previous cell dealt with this for the categorical data -> in which the mean healthcare expenses for patients were plotted against these demographics in bar charts\n",
        "\t\t-> The code in this cell does the same but for the numerical data in the set\n",
        "\t\t\t-> In which case we can now create scatter plots rather than bar charts\n",
        "\t\t\t-> This data contains different customer demographics than the previous cell does (age, BMI and the number of children per customer)\n",
        "\n",
        "\tGenerating subplots with Python:\n",
        "\t\t-> This code works the same as in the previous cell (please refer to the annotations for the code in the previous cell for explanations on this)\n",
        "\t\t\t-> dataset is the dataset which stores the healthcare information\n",
        "\t\t\t-> We are iterating through the columns of this set -> and if the column which we are iterating through is the expenses column and if it's not categorical data, then we are storing it in the variable called cols\n",
        "\t\t\t\t-> This is the variable which we then iterate through to create the 1x3 matrix of subplots\n",
        "\t\t\t\t-> But this time when we iterate through the data we are creating scatter plots and not bar charts\n",
        "\t\t\t\t-> All of these scatter plots are being created with the same (expenses) data on the y-axis\n",
        "\t\t\t\t\t-> This is set when each scatter plot is created, rather than when the columns being iterated through are selected\n",
        "\n",
        "\tFrom this, we can see:\n",
        "\t\t-> The older patients become, the higher their healthcare expenses are\n",
        "\t\t-> The higher the BMI of patients, the higher their healthcare expenses\n",
        "\t\t-> The less children people have, the higher their healthcare expenses are\n",
        "\t\t\t-> This may indicate a more disposable income among people with less children, and therefore a higher investment in healthcare expenses among this demographic\n",
        "\"\"\"\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 4))\n",
        "cols = [f for f in dataset.columns if f!= 'expenses' and dataset[f].dtype != 'object']\n",
        "for i, feature in enumerate(cols):\n",
        "    dataset.plot.scatter(x=feature,y='expenses',ax=axes[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "W4_ff9_1q8F-",
        "outputId": "c9677647-750a-4d3e-98d9-d97c1cdbf77c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1296x288 with 3 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\t-> The dataset was previously stored in a variable called dataset\n",
        "\t-> This cell takes this dataset and stores a copy of it in a variable called df\n",
        "\t-> This section of the notebook explored the data\n",
        "\t\t-> We have the healthcare expenses of US patients\n",
        "\t\t-> This is according to six patient demographics\n",
        "\t\t-> Three of these are categorical and graphed on the bar charts in this section\n",
        "\t\t-> Thee of these are numerical and graphed in the scatter plots above\n",
        "\t-> The next section of the notebook cleans this data to train the model on\n",
        "\"\"\"\n",
        "\n",
        "df = dataset.copy()"
      ],
      "metadata": {
        "id": "7OT5tqJcQOJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Preprocessing Data for Training the Machine Learning Model"
      ],
      "metadata": {
        "id": "4n7H3b2mvG2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing data\n",
        "\n",
        "\"\"\"\n",
        "\tWhat this cell does:\n",
        "\t-> We are cleaning the data for pre-processing, before training the model\n",
        "\t-> We are taking the df data frame defined in the previous cell which is a copy of the main data frame (stored in `dataframe` for the project) and converting all of its categorical data into numerical data\n",
        "\t\t-> Then having it return us a dictionary which tells us how to get from the coded form of that categorical data, back to the categorical form of the data\n",
        "\t\t-> We need all of the data in numerical form so that we can train the model on it -> this is removing the categorical data\n",
        "\t\t-> This is stored in the variable called `df`, but the original `dataframe` still contains categorical data\n",
        "\n",
        "\tThe approach used to code the Python in this cell:\n",
        "\t\t-> We are first dealing with the categorical data (the three variables which we plotted in bar charts which are stored in strings)\n",
        "\t-> We are storing the information about that categorical data in the empty dictionary called feature_columns\n",
        "\t\t-> We are then iterating through each of the columns in the data frame df for all of the data\n",
        "\t\t-> Then we are populating the dictionary feature_columns with that information\n",
        "\t\t\t-> So for one column:\n",
        "\t\t\t\t-> If the data stored in that column are categorical\n",
        "\t\t\t\t-> That is, the name of the data which is stored in that column is in a string format or an 'object' -> then the data which the column contains is categorical\n",
        "\t\t\t\t-> In which case, we set the entire column equal to a variable c, which is a pandas categorical type\n",
        "\t\t\t\t-> We then replace the original column in the dataset with this -> to replace the categorical data which it represents with numerical data for our machine learning model\n",
        "\t\t\t\t-> We are doing this for the dataset called df -> which is a copy of the original one called dataset\n",
        "\t\t\t\t\t-> dataset will contain categorical and numerical data\n",
        "\t\t\t\t\t-> We are now altering df (which is the copy of it), so that it only contains numerical data\n",
        "\t\t\t\t\t-> we are setting it equal to the codes of this (converting the categorical data into numerical data)\n",
        "\t\t\t\t-> We are then adding the code for this column -> the code which converts its categorical value to its numerical value, into a dictionary\n",
        "\t\t\t\t-> So we end up with the df data frame which contains no categorical data (only numerical data), and a dictionary which tells us how to convert between the codes for the three pieces of categorical data - to what their original values were\n",
        "\t\t\t\t-> We need all of the data which we are training the model on to be in numerical form (not categorical form)\n",
        "\"\"\"\n",
        "\n",
        "feature_columns = {}\n",
        "for col_name in df.columns:\n",
        "    if(df[col_name].dtype == 'object'):\n",
        "        c = df[col_name].astype('category')\n",
        "        df[col_name] = c.cat.codes\n",
        "        feature_columns[col_name] = dict(enumerate(c.cat.categories))"
      ],
      "metadata": {
        "id": "B6DgZ3ZoNW5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the convertion of categorical data to numerical values\n",
        "\"\"\"\n",
        "\t-> This cell returns the head of the data frame which the previous cell created\n",
        "\t-> This got rid of the categorical data in the data frame and replaced it with itself, in coded form\n",
        "\"\"\"\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "L1Fhir2XHR4x",
        "outputId": "1360e9d2-232f-4767-8e33-9d68e8038d40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-52497164-0efe-423c-9708-8bf02f074a63\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>expenses</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>27.9</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>16884.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>33.8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1725.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>1</td>\n",
              "      <td>33.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4449.46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "      <td>22.7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>21984.47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "      <td>28.9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3866.86</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52497164-0efe-423c-9708-8bf02f074a63')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-52497164-0efe-423c-9708-8bf02f074a63 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-52497164-0efe-423c-9708-8bf02f074a63');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   age  sex   bmi  children  smoker  region  expenses\n",
              "0   19    0  27.9         0       1       3  16884.92\n",
              "1   18    1  33.8         1       0       2   1725.55\n",
              "2   28    1  33.0         3       0       2   4449.46\n",
              "3   33    1  22.7         0       0       1  21984.47\n",
              "4   32    1  28.9         0       0       1   3866.86"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check dictionary of encoding for categorical features\n",
        "\n",
        "\"\"\"\n",
        "\t-> In the previous cell when we were going from the data frame with categorical and numerical values to the data frame with numerical values only, we defined a dictionary called `feature_columns`\n",
        "\t-> This dictionary allows us to convert between the data which was in categorical form and its numerical equivalent\n",
        "\t-> This cell prints out that dictionary\n",
        "\t\t-> The categorical data is the data which describes whether the patients are smokers, where they live and their sex\n",
        "\"\"\"\n",
        "\n",
        "feature_columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4Yp695KhsOx",
        "outputId": "b4122bf7-da0b-4620-d850-cefd9e05dd5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'region': {0: 'northeast', 1: 'northwest', 2: 'southeast', 3: 'southwest'},\n",
              " 'sex': {0: 'female', 1: 'male'},\n",
              " 'smoker': {0: 'no', 1: 'yes'}}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting data in training and testing datasets\n",
        "\n",
        "\"\"\"\n",
        "\tOutline:\n",
        "\t\t-> Now we have the dataset in numerical form, we are converting it into training and test datasets\n",
        "\t\t-> We want 80% of the data to be used to train the model, and 20% of the data to be used to test the model\n",
        "\t\t-> We are training the model on the data, and we want it to be used to predict the expenses that a specific patient will accrue based off of their demographics\n",
        "\t\t\t-> The `target variable, label` which we want to predict is the expenses\n",
        "\t\t\t-> And then the `features` are the demographics of the patient which we input into the model to make its predictions -> the age of the patient, where they live etc\n",
        "\n",
        "\tHow we do this is:\n",
        "\t\t-> The entire numerical data frame is called df\n",
        "\t\t-> We want four things\n",
        "\t\t\t-> The test dataset (80% of this total dataset)\n",
        "\t\t\t-> The training dataset (20% of this total dataset)\n",
        "\t\t\t-> Then both of those without the data which we want the model to predict (the healthcare expenses)\n",
        "\t\t-> The top line of code in this cell gives us a random data frame with 80% of the rows in it in the total data frame <- this is the training data set\n",
        "\t\t-> The next line of code gives us the test dataset <- which is the main dataset without the rows which the training dataset has\n",
        "\t\t\t-> This is created with the .drop method on the df data frame\n",
        "\t\t-> The next two lines are setting these datasets equal to datasets with other names\n",
        "\t\t-> Then the bottom block of code in this cell (the final two lines) gives us two more datasets, which are those same datasets but without the expenses data (this is what we are predicting)\n",
        "\t\t\t-> The pop method sets the dataset equal to itself, but without the column / data which was popped off\n",
        "\"\"\"\n",
        "\n",
        "train_features = df.sample(frac=0.8, random_state=0)\n",
        "test_features = df.drop(train_features.index)\n",
        "train_dataset = train_features.copy()\n",
        "test_dataset = test_features.copy()\n",
        "\n",
        "train_labels = train_dataset.pop('expenses')\n",
        "test_labels = test_dataset.pop('expenses')"
      ],
      "metadata": {
        "id": "_lfKSqaSZYSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build data normalizer\n",
        "\n",
        "\"\"\"\n",
        "\tThe concept of normalising the data as part of preprocessing:\n",
        "\t\t-> We imported the data into the data frame\n",
        "\t\t-> Then got rid of all of the categorical data and converted it all into numerical data <- you can't perform linear regression on categorical data in this case\n",
        "\t\t-> Then we converted that data frame into test and training sets\n",
        "\t\t-> In this cell we are using the TensorFlow module to normalise all of its data -> so that when we train the model it will have more stability and improve the convergence\n",
        "\t\t-> This scales the input features to have a mean of 0 and a standard deviation of 1 (rather than standardisation which is to make the magnitude of all of the datapoints fall in that range)\n",
        "\t\t-> We are forcing the data into a normal distribution using TensorFlow\n",
        "\t\t-> This is the last stage of data preprocessing for our model\n",
        "\n",
        "\tUsing Python and TensorFlow to do this:\n",
        "\t\t-> The first line sets a normalisation layer\n",
        "\t\t-> That normalisation layer is equal to a variable\n",
        "\t\t-> When we later define the architecture of the model, this `variable` can be applied and it will normalise the data\n",
        "\t\t\t-> It's targeting the final axis of the input data\n",
        "\t\t\t-> This is set with the axis = -1\n",
        "\t\t\t-> This is how we target the numerical features in each sample\n",
        "\t\t-> The second line in this cell uses the adapt method to calculate the mean and standard deviation of the training dataset\n",
        "\t\t\t-> These are valleys which we use when training the data set -> to ensure that numerical values at different layers in the model are normalised\n",
        "\t\t\t-> This returns those values, for later use\n",
        "\t\t\t-> We also have that entire layer stored in the variable called `normalizer`\n",
        "\t\t\t-> This line converts the train dataset from a pandas data frame into a numpy array and is used to calculate its mean and standard deviation (refer to the definition of normalisation in this context above)\n",
        "\t\t-> This configures the normalisation layer with the mean and standard deviation of the training dataset\n",
        "\t\t\t-> The aim is to make sure that while the model is being trained, all of our data remains normalised\n",
        "\"\"\"\n",
        "\n",
        "normalizer = layers.Normalization(axis=-1)\n",
        "normalizer.adapt(np.array(train_dataset))"
      ],
      "metadata": {
        "id": "yw2HYb9fhKrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Initialise the Architecture to Train the Model"
      ],
      "metadata": {
        "id": "_AMGEtTnvOSg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model architecture\n",
        "\n",
        "\"\"\"\n",
        "\tIn this cell, we define the model's architecture:\n",
        "\t\t-> We are building a neural network which is trained on the demographics of the patient data -> and then outputs a prediction for what their healthcare expenses will be\n",
        "\t\t-> This is to be trained on the data we just cleaned (for the patient healthcare expenses by demographics)\n",
        "\t\t-> We are defining the architecture for the model before training it and putting any data into it -> this is what this section does\n",
        "\n",
        "\tThe architecture of the model:\n",
        "\t\t-> This cell sets the architecture for the model -> we are using two hidden layers for this\n",
        "\t\t-> We are building the neural network using Keras (TensorFlow)\n",
        "\t\t-> The argument of the function is a layer which normalises the data in that segment of the neural network\n",
        "\t\t-> The model is defined in a variable\n",
        "\t\t\t-> A variable called `model` is set, which stores all of the different layers of the neural network\n",
        "\t\t\t-> Each of the lines of code in what that variable equals is a layer of the neural network\n",
        "\t\t-> The architecture of those layers\n",
        "\t\t\t-> The first layer of the network is a normalisation layer (refer to the points in the previous section for this)\n",
        "\t\t\t-> We then have two dense (fully connected) layers -> and each of these has 64 neurones and a ReLU activation function\n",
        "\t\t\t-> The final layer of this is a dense layer with one neurone, considering that we are predicting one value (the health care expenditure of a patient)\n",
        "\t\t\t-> The ReLU activation function gets rid of all of the negatives and makes them zeros -> we want the output of the model to be a positive expenditure value\n",
        "\n",
        "\tCompiling the neural network:\n",
        "\t\t-> We first set the architecture for the neural network\n",
        "\t\t-> Now we are telling it which algorithms to run when the data is passed through it\n",
        "\t\t-> What to optimise for, and which optimisation algorithms to use\n",
        "\t\t-> In the argument for this section of code, we are telling it what loss function to use (the function we use to calculate how accurate or inaccurate the predictions are)\n",
        "\t\t\t-> We are telling it which optimisation algorithm to use to perform gradient descent -> in this case it's the Adam algorithm (we are also telling it what learning rate to use for this when performing gradient descent)\n",
        "\t\t\t-> And finally, we are telling it what metrics to optimise for -> in this case it's the MAE (Mean Absolute Error) and the Mean Squared Error (MSE)\n",
        "\t\t\t-> The parameters which we are compiling this model are the ones which are the most common for neural networks which use linear regression\n",
        "\t\t\t-> This compilation is again performed with the .compile TensorFlow method\n",
        "\n",
        "\tReturning the model:\n",
        "\t\t-> Our function returns the model\n",
        "\t\t-> Model is another term for neural network\n",
        "\t\t-> It returns the architecture of the network, combined with the algorithm which we want to use to perform linear regression\n",
        "\t\t-> The model which it's returning contains two hidden layers and returns one number (the predicted healthcare expenses for the input patient)\n",
        "\t\t-> This entire function is just to define the architecture of the model (not including any data)\n",
        "\t\t-> The reason we are defining it in a function is so that we can input the normalisation into it -> this is so that the mean and standard deviation of the data which is passed into it is normalised\n",
        "\t\t\t-> We are passing in data about the sex, age, BMI, number of children etc -> a lot of different data about the patient demographics, so if we are normalising all of these - it makes more sense to define a function which takes a normalisation layer as the input\n",
        "\t\t\t-> Each of these different metrics will affect the healthcare expenses of the patient (what we are trying to predict), combined with it being a linear regression model - which means each feature will have a different linear regression equation in relation to those healthcare expenses\n",
        "\"\"\"\n",
        "\n",
        "def build_and_compile_model(norm):\n",
        "  model = keras.Sequential([\n",
        "      norm,\n",
        "      layers.Dense(64, activation='relu'),\n",
        "      layers.Dense(64, activation='relu'),\n",
        "      layers.Dense(1)\n",
        "  ])\n",
        "\n",
        "  model.compile(loss='mean_absolute_error',\n",
        "                optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "                metrics=['mae', 'mse'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "fE8hdO87PqT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build and compile model\n",
        "\n",
        "\"\"\"\n",
        "\tThis cell initialises the architecture of the model we are going to use: <- but hasn't yet trained the model on this\n",
        "\t\t-> The previous cell defined a function called `build_and_compile_model`\n",
        "\t\t-> This function generates neural networks based on an architecture with two hidden layers, then inputs a normalisation layer\n",
        "\t\t-> This cell calls this function, to initialise the neural network for the project\n",
        "\t\t-> This sets it equal to a variable called `model` -> which we haven't trained yet, but which stores the architecture for the network we want to use\n",
        "\t\t-> The second line of code in this cell prints out a summary of this architecture\n",
        "\t\t-> It hasn't been trained on data yet - but its architecture has been initialised, and we have also compiled it in the sense that we've given it the loss function and algorithm for gradient descent to use\n",
        "\n",
        "\tWe currently have:\n",
        "\t\t-> The test and train datasets -> with and without the expenses column which we want the model to predict\n",
        "\t\t-> The architecture for the neural network which we want to use to train the model with\n",
        "\t\t-> We first imported the modules and data, then cleaned the data in a form which a neural network could understand (normalised it, got rid of the categorical data), then initialised the architecture for the neural network to train the model on\n",
        "\t\t-> The next stage is training the neural network with this data and linear regression, then using it to make predictions and running unit tests to ensure that this is valid\n",
        "\"\"\"\n",
        "\n",
        "model = build_and_compile_model(normalizer)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndlAx2SxjpqL",
        "outputId": "f16fcdb3-1a9d-4640-f327-7e1e9c6d90b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " normalization (Normalizatio  (None, 6)                13        \n",
            " n)                                                              \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 64)                448       \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,686\n",
            "Trainable params: 4,673\n",
            "Non-trainable params: 13\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Training the Model Using a Linear Regression Approach"
      ],
      "metadata": {
        "id": "uBpJVmvOvZx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "\n",
        "\"\"\"\n",
        "  -> Context:\n",
        "\t  -> The previous cell initialised the architecture for the neural network which the model uses\n",
        "\t  -> The cells before this cleaned the data which we are going to use here to train the model\n",
        "\t  -> We are performing linear regression using the cleaned, normalised and formatted dataset which was defined earlier in the notebook\n",
        "\t  -> This cell is training the model on this dataset\n",
        "\t  -> Since there are many patient demographics, we do not just perform one linear regression and calculate a line of best fit to make these predictions (we need an entire model with multiple layers)\n",
        "\t  -> We are using the TensorFlow method called .fit to train the model in this cell, with the dataset being stored in the variable called model\n",
        "\t  -> We are setting this entire trained model equal to the variable called history\n",
        "\t  -> The function which we defined two cells ago was to initialise the architecture for the neural network the model uses to do this -> this entire function was defined to generate different neural networks (not to train the model)\n",
        "\t  -> What we use to train the model is the .fit TensorFlow method\n",
        "\n",
        "\t-> The arguments this uses are:\n",
        "\t\t-> The dataset we are training the neural network on <- this was the cleaned data from earlier\n",
        "\t\t\t-> We are training it on the dataset which doesn't include what we are predicting (the healthcare expenditures)\n",
        "\t\t\t-> We popped this information off of this dataset earlier -> so the only remaining data are the features which we are predicting\n",
        "\t\t-> The labels with the features for the patient demographics <- these are the features in the dataset which aren't in the healthcare expenditures column\n",
        "\t\t-> The percentage of that training data which we reserve for validating the model <- we use this when comparing the number of epochs used to train the dataset with in comparison to the accuracy of the model\n",
        "\t\t-> The number of epochs we want the model to use -> this is the number of times it trains itself on the same data -> going through the entire dataset\n",
        "\t\t\t-> If this number is too high then we run the risk of overfitting the model on the same piece of data\n",
        "\t\t\t-> If this number is too low, we could be limiting the accuracy of the model\n",
        "\t\t\t-> When we are training the model, it goes through the entire dataset 600 times - so we can see how it performs with this number (we plot the behaviour of this later)\n",
        "\t\t-> We are setting the verbosity parameter equal to 1 -> when we train the model it will output the progress and information about this, per epoch it completes\n",
        "\n",
        "\t-> This variable (`history`) is now storing information about how the model performs per epoch of its training -> which we can graph for more information about the optimal number of epochs\n",
        "\"\"\"\n",
        "\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    train_labels,\n",
        "    validation_split=0.2,\n",
        "    verbose=1, epochs=600)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEYqvS_-k531",
        "outputId": "7c00d1c9-7a53-40ed-9c65-dd6302a8f168"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/600\n",
            "27/27 [==============================] - 1s 12ms/step - loss: 12712.0811 - mae: 12712.0811 - mse: 301879296.0000 - val_loss: 14426.8320 - val_mae: 14426.8320 - val_mse: 363280800.0000\n",
            "Epoch 2/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 12708.7334 - mae: 12708.7334 - mse: 301786848.0000 - val_loss: 14421.8320 - val_mae: 14421.8320 - val_mse: 363127296.0000\n",
            "Epoch 3/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 12701.6904 - mae: 12701.6904 - mse: 301596960.0000 - val_loss: 14411.8623 - val_mae: 14411.8623 - val_mse: 362822624.0000\n",
            "Epoch 4/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 12688.6436 - mae: 12688.6436 - mse: 301244992.0000 - val_loss: 14394.5020 - val_mae: 14394.5020 - val_mse: 362301504.0000\n",
            "Epoch 5/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 12666.7285 - mae: 12666.7285 - mse: 300657664.0000 - val_loss: 14366.5674 - val_mae: 14366.5674 - val_mse: 361472128.0000\n",
            "Epoch 6/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 12632.6729 - mae: 12632.6729 - mse: 299754688.0000 - val_loss: 14324.6729 - val_mae: 14324.6729 - val_mse: 360236352.0000\n",
            "Epoch 7/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 12583.1006 - mae: 12583.1006 - mse: 298465600.0000 - val_loss: 14265.7783 - val_mae: 14265.7783 - val_mse: 358511296.0000\n",
            "Epoch 8/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 12514.6680 - mae: 12514.6680 - mse: 296688896.0000 - val_loss: 14186.1797 - val_mae: 14186.1797 - val_mse: 356220992.0000\n",
            "Epoch 9/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 12424.0830 - mae: 12424.0830 - mse: 294363616.0000 - val_loss: 14082.8936 - val_mae: 14082.8936 - val_mse: 353288800.0000\n",
            "Epoch 10/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 12308.0459 - mae: 12308.0459 - mse: 291486304.0000 - val_loss: 13953.1182 - val_mae: 13953.1182 - val_mse: 349622592.0000\n",
            "Epoch 11/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 12163.3086 - mae: 12163.3086 - mse: 287911008.0000 - val_loss: 13793.7451 - val_mae: 13793.7451 - val_mse: 345234816.0000\n",
            "Epoch 12/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 11987.4355 - mae: 11987.4355 - mse: 283624736.0000 - val_loss: 13601.2432 - val_mae: 13601.2432 - val_mse: 340040576.0000\n",
            "Epoch 13/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 11776.0000 - mae: 11776.0000 - mse: 278628512.0000 - val_loss: 13375.2500 - val_mae: 13375.2500 - val_mse: 333964576.0000\n",
            "Epoch 14/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 11528.9092 - mae: 11528.9092 - mse: 272926112.0000 - val_loss: 13115.0176 - val_mae: 13115.0176 - val_mse: 327027968.0000\n",
            "Epoch 15/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 11258.0820 - mae: 11258.0820 - mse: 266540944.0000 - val_loss: 12824.6562 - val_mae: 12824.6562 - val_mse: 319290624.0000\n",
            "Epoch 16/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 10972.7422 - mae: 10972.7422 - mse: 259478496.0000 - val_loss: 12513.7715 - val_mae: 12513.7715 - val_mse: 310819872.0000\n",
            "Epoch 17/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 10673.7910 - mae: 10673.7910 - mse: 251736912.0000 - val_loss: 12186.7324 - val_mae: 12186.7324 - val_mse: 301773024.0000\n",
            "Epoch 18/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 10363.1904 - mae: 10363.1904 - mse: 243580240.0000 - val_loss: 11845.5479 - val_mae: 11845.5479 - val_mse: 291952800.0000\n",
            "Epoch 19/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 10033.2256 - mae: 10033.2256 - mse: 234967120.0000 - val_loss: 11478.7822 - val_mae: 11478.7822 - val_mse: 281402592.0000\n",
            "Epoch 20/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 9682.5967 - mae: 9682.5967 - mse: 225747232.0000 - val_loss: 11084.1973 - val_mae: 11084.1973 - val_mse: 270290048.0000\n",
            "Epoch 21/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 9309.4629 - mae: 9309.4629 - mse: 215870224.0000 - val_loss: 10663.8447 - val_mae: 10663.8447 - val_mse: 258771760.0000\n",
            "Epoch 22/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 8928.8066 - mae: 8928.8066 - mse: 205931872.0000 - val_loss: 10223.2520 - val_mae: 10223.2520 - val_mse: 246815856.0000\n",
            "Epoch 23/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 8538.2754 - mae: 8538.2754 - mse: 195856416.0000 - val_loss: 9774.6357 - val_mae: 9774.6357 - val_mse: 234578528.0000\n",
            "Epoch 24/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 8153.1768 - mae: 8153.1768 - mse: 185608848.0000 - val_loss: 9320.3232 - val_mae: 9320.3232 - val_mse: 222383728.0000\n",
            "Epoch 25/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 7766.7354 - mae: 7766.7354 - mse: 175177536.0000 - val_loss: 8873.8164 - val_mae: 8873.8164 - val_mse: 210294480.0000\n",
            "Epoch 26/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 7390.6455 - mae: 7390.6455 - mse: 164869200.0000 - val_loss: 8442.0674 - val_mae: 8442.0674 - val_mse: 198428048.0000\n",
            "Epoch 27/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 7029.3306 - mae: 7029.3306 - mse: 155279072.0000 - val_loss: 7999.2598 - val_mae: 7999.2598 - val_mse: 186182720.0000\n",
            "Epoch 28/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 6678.8472 - mae: 6678.8472 - mse: 145425248.0000 - val_loss: 7588.0479 - val_mae: 7588.0479 - val_mse: 175564000.0000\n",
            "Epoch 29/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 6358.4971 - mae: 6358.4971 - mse: 136625456.0000 - val_loss: 7193.7124 - val_mae: 7193.7124 - val_mse: 165223152.0000\n",
            "Epoch 30/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 6061.5977 - mae: 6061.5977 - mse: 128084400.0000 - val_loss: 6841.8413 - val_mae: 6841.8413 - val_mse: 155426416.0000\n",
            "Epoch 31/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 5802.8130 - mae: 5802.8130 - mse: 120865856.0000 - val_loss: 6518.7212 - val_mae: 6518.7212 - val_mse: 146312640.0000\n",
            "Epoch 32/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 5563.0562 - mae: 5563.0562 - mse: 113927800.0000 - val_loss: 6236.8701 - val_mae: 6236.8701 - val_mse: 138545520.0000\n",
            "Epoch 33/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 5340.9058 - mae: 5340.9058 - mse: 107766592.0000 - val_loss: 5976.7393 - val_mae: 5976.7393 - val_mse: 131223992.0000\n",
            "Epoch 34/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 5137.9951 - mae: 5137.9951 - mse: 101952424.0000 - val_loss: 5753.4395 - val_mae: 5753.4395 - val_mse: 124303344.0000\n",
            "Epoch 35/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 4956.1064 - mae: 4956.1064 - mse: 96909688.0000 - val_loss: 5548.2534 - val_mae: 5548.2534 - val_mse: 118072168.0000\n",
            "Epoch 36/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 4785.1704 - mae: 4785.1704 - mse: 92116744.0000 - val_loss: 5353.9604 - val_mae: 5353.9604 - val_mse: 112266176.0000\n",
            "Epoch 37/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 4613.8716 - mae: 4613.8716 - mse: 87537032.0000 - val_loss: 5165.3594 - val_mae: 5165.3594 - val_mse: 106693576.0000\n",
            "Epoch 38/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 4450.7568 - mae: 4450.7568 - mse: 83043416.0000 - val_loss: 4964.4468 - val_mae: 4964.4468 - val_mse: 101187760.0000\n",
            "Epoch 39/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 4290.1226 - mae: 4290.1226 - mse: 78932432.0000 - val_loss: 4767.9248 - val_mae: 4767.9248 - val_mse: 95628200.0000\n",
            "Epoch 40/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 4135.4287 - mae: 4135.4287 - mse: 74495232.0000 - val_loss: 4578.9292 - val_mae: 4578.9292 - val_mse: 90746544.0000\n",
            "Epoch 41/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 3990.7336 - mae: 3990.7336 - mse: 70858552.0000 - val_loss: 4402.9741 - val_mae: 4402.9741 - val_mse: 85626736.0000\n",
            "Epoch 42/600\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 3849.4541 - mae: 3849.4541 - mse: 66828296.0000 - val_loss: 4255.3145 - val_mae: 4255.3145 - val_mse: 81196712.0000\n",
            "Epoch 43/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 3735.1331 - mae: 3735.1331 - mse: 63581816.0000 - val_loss: 4136.2734 - val_mae: 4136.2734 - val_mse: 77343944.0000\n",
            "Epoch 44/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 3643.7012 - mae: 3643.7012 - mse: 60569876.0000 - val_loss: 4036.3108 - val_mae: 4036.3108 - val_mse: 73576584.0000\n",
            "Epoch 45/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 3572.8418 - mae: 3572.8418 - mse: 58028692.0000 - val_loss: 3959.7908 - val_mae: 3959.7908 - val_mse: 70867488.0000\n",
            "Epoch 46/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 3520.3696 - mae: 3520.3696 - mse: 56093696.0000 - val_loss: 3909.6250 - val_mae: 3909.6250 - val_mse: 68839600.0000\n",
            "Epoch 47/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 3480.0630 - mae: 3480.0630 - mse: 54604072.0000 - val_loss: 3876.3062 - val_mae: 3876.3062 - val_mse: 66822212.0000\n",
            "Epoch 48/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 3447.2705 - mae: 3447.2705 - mse: 52867812.0000 - val_loss: 3843.1604 - val_mae: 3843.1604 - val_mse: 64908948.0000\n",
            "Epoch 49/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 3413.2241 - mae: 3413.2241 - mse: 51839488.0000 - val_loss: 3822.4592 - val_mae: 3822.4592 - val_mse: 63685892.0000\n",
            "Epoch 50/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 3390.4326 - mae: 3390.4326 - mse: 51047252.0000 - val_loss: 3801.3738 - val_mae: 3801.3738 - val_mse: 62794752.0000\n",
            "Epoch 51/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 3370.2390 - mae: 3370.2390 - mse: 50000928.0000 - val_loss: 3781.8254 - val_mae: 3781.8254 - val_mse: 61212852.0000\n",
            "Epoch 52/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 3349.2095 - mae: 3349.2095 - mse: 49086320.0000 - val_loss: 3759.1389 - val_mae: 3759.1389 - val_mse: 60237820.0000\n",
            "Epoch 53/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 3330.4944 - mae: 3330.4944 - mse: 48381740.0000 - val_loss: 3745.8696 - val_mae: 3745.8696 - val_mse: 59350096.0000\n",
            "Epoch 54/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 3313.6736 - mae: 3313.6736 - mse: 47456388.0000 - val_loss: 3728.3774 - val_mae: 3728.3774 - val_mse: 58278532.0000\n",
            "Epoch 55/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 3295.4890 - mae: 3295.4890 - mse: 46668460.0000 - val_loss: 3715.6401 - val_mae: 3715.6401 - val_mse: 57267244.0000\n",
            "Epoch 56/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 3280.5525 - mae: 3280.5525 - mse: 45960860.0000 - val_loss: 3701.4609 - val_mae: 3701.4609 - val_mse: 56399772.0000\n",
            "Epoch 57/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 3264.6284 - mae: 3264.6284 - mse: 45398552.0000 - val_loss: 3687.9558 - val_mae: 3687.9558 - val_mse: 55589448.0000\n",
            "Epoch 58/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 3250.7131 - mae: 3250.7131 - mse: 44743592.0000 - val_loss: 3675.2310 - val_mae: 3675.2310 - val_mse: 54763692.0000\n",
            "Epoch 59/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 3237.1218 - mae: 3237.1218 - mse: 44103260.0000 - val_loss: 3663.6306 - val_mae: 3663.6306 - val_mse: 53970236.0000\n",
            "Epoch 60/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 3224.3584 - mae: 3224.3584 - mse: 43730508.0000 - val_loss: 3653.3479 - val_mae: 3653.3479 - val_mse: 53502692.0000\n",
            "Epoch 61/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 3213.9355 - mae: 3213.9355 - mse: 43162756.0000 - val_loss: 3639.5776 - val_mae: 3639.5776 - val_mse: 52678896.0000\n",
            "Epoch 62/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 3201.5789 - mae: 3201.5789 - mse: 42486160.0000 - val_loss: 3627.9075 - val_mae: 3627.9075 - val_mse: 51888820.0000\n",
            "Epoch 63/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 3187.9678 - mae: 3187.9678 - mse: 42078028.0000 - val_loss: 3615.0908 - val_mae: 3615.0908 - val_mse: 51397264.0000\n",
            "Epoch 64/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 3177.3110 - mae: 3177.3110 - mse: 41525460.0000 - val_loss: 3604.5474 - val_mae: 3604.5474 - val_mse: 50597304.0000\n",
            "Epoch 65/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 3164.3440 - mae: 3164.3440 - mse: 40934272.0000 - val_loss: 3591.3899 - val_mae: 3591.3899 - val_mse: 49911320.0000\n",
            "Epoch 66/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 3153.7703 - mae: 3153.7703 - mse: 40476604.0000 - val_loss: 3580.2769 - val_mae: 3580.2769 - val_mse: 49218708.0000\n",
            "Epoch 67/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 3142.1992 - mae: 3142.1992 - mse: 39922524.0000 - val_loss: 3572.4744 - val_mae: 3572.4744 - val_mse: 48550172.0000\n",
            "Epoch 68/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 3130.3567 - mae: 3130.3567 - mse: 39445544.0000 - val_loss: 3555.3215 - val_mae: 3555.3215 - val_mse: 48099752.0000\n",
            "Epoch 69/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 3119.9954 - mae: 3119.9954 - mse: 38957376.0000 - val_loss: 3546.6843 - val_mae: 3546.6843 - val_mse: 47376928.0000\n",
            "Epoch 70/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 3107.4929 - mae: 3107.4929 - mse: 38557900.0000 - val_loss: 3536.1047 - val_mae: 3536.1047 - val_mse: 46745332.0000\n",
            "Epoch 71/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 3095.7764 - mae: 3095.7764 - mse: 38014068.0000 - val_loss: 3524.8257 - val_mae: 3524.8257 - val_mse: 46014764.0000\n",
            "Epoch 72/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 3085.6252 - mae: 3085.6252 - mse: 37432128.0000 - val_loss: 3508.7273 - val_mae: 3508.7273 - val_mse: 45418380.0000\n",
            "Epoch 73/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 3073.5813 - mae: 3073.5813 - mse: 37145656.0000 - val_loss: 3503.3708 - val_mae: 3503.3708 - val_mse: 44865492.0000\n",
            "Epoch 74/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 3063.8020 - mae: 3063.8020 - mse: 36748412.0000 - val_loss: 3489.3442 - val_mae: 3489.3442 - val_mse: 44438620.0000\n",
            "Epoch 75/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 3052.4180 - mae: 3052.4180 - mse: 36328624.0000 - val_loss: 3476.1729 - val_mae: 3476.1729 - val_mse: 44008424.0000\n",
            "Epoch 76/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 3043.5779 - mae: 3043.5779 - mse: 36055164.0000 - val_loss: 3468.4443 - val_mae: 3468.4443 - val_mse: 43509936.0000\n",
            "Epoch 77/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 3031.8379 - mae: 3031.8379 - mse: 35642436.0000 - val_loss: 3457.4792 - val_mae: 3457.4792 - val_mse: 42913760.0000\n",
            "Epoch 78/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 3020.0017 - mae: 3020.0017 - mse: 35325740.0000 - val_loss: 3443.3542 - val_mae: 3443.3542 - val_mse: 42554420.0000\n",
            "Epoch 79/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 3010.0059 - mae: 3010.0059 - mse: 35068984.0000 - val_loss: 3434.6091 - val_mae: 3434.6091 - val_mse: 42246000.0000\n",
            "Epoch 80/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2998.2568 - mae: 2998.2568 - mse: 34738756.0000 - val_loss: 3419.1951 - val_mae: 3419.1951 - val_mse: 41780160.0000\n",
            "Epoch 81/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2987.8154 - mae: 2987.8154 - mse: 34454660.0000 - val_loss: 3409.2295 - val_mae: 3409.2295 - val_mse: 41413932.0000\n",
            "Epoch 82/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2976.7383 - mae: 2976.7383 - mse: 34235864.0000 - val_loss: 3394.5164 - val_mae: 3394.5164 - val_mse: 41151224.0000\n",
            "Epoch 83/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2966.4424 - mae: 2966.4424 - mse: 34056848.0000 - val_loss: 3386.7332 - val_mae: 3386.7332 - val_mse: 40766664.0000\n",
            "Epoch 84/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2957.4543 - mae: 2957.4543 - mse: 33742636.0000 - val_loss: 3373.4197 - val_mae: 3373.4197 - val_mse: 40486672.0000\n",
            "Epoch 85/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2945.5693 - mae: 2945.5693 - mse: 33565556.0000 - val_loss: 3358.4966 - val_mae: 3358.4966 - val_mse: 40209832.0000\n",
            "Epoch 86/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2933.9377 - mae: 2933.9377 - mse: 33453334.0000 - val_loss: 3346.4731 - val_mae: 3346.4731 - val_mse: 40050064.0000\n",
            "Epoch 87/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2922.7788 - mae: 2922.7788 - mse: 33344382.0000 - val_loss: 3334.4331 - val_mae: 3334.4331 - val_mse: 39801880.0000\n",
            "Epoch 88/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2912.3286 - mae: 2912.3286 - mse: 33268470.0000 - val_loss: 3326.8721 - val_mae: 3326.8721 - val_mse: 39652204.0000\n",
            "Epoch 89/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2902.9370 - mae: 2902.9370 - mse: 33176622.0000 - val_loss: 3312.5315 - val_mae: 3312.5315 - val_mse: 39558940.0000\n",
            "Epoch 90/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2891.6499 - mae: 2891.6499 - mse: 33123988.0000 - val_loss: 3296.4211 - val_mae: 3296.4211 - val_mse: 39443576.0000\n",
            "Epoch 91/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2880.7288 - mae: 2880.7288 - mse: 33095146.0000 - val_loss: 3288.0449 - val_mae: 3288.0449 - val_mse: 39400664.0000\n",
            "Epoch 92/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2871.6804 - mae: 2871.6804 - mse: 33184474.0000 - val_loss: 3275.3625 - val_mae: 3275.3625 - val_mse: 39439076.0000\n",
            "Epoch 93/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2862.4678 - mae: 2862.4678 - mse: 33205918.0000 - val_loss: 3255.8826 - val_mae: 3255.8826 - val_mse: 39417452.0000\n",
            "Epoch 94/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2849.5164 - mae: 2849.5164 - mse: 33245882.0000 - val_loss: 3249.3003 - val_mae: 3249.3003 - val_mse: 39442956.0000\n",
            "Epoch 95/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2839.7161 - mae: 2839.7161 - mse: 33336124.0000 - val_loss: 3233.8220 - val_mae: 3233.8220 - val_mse: 39498088.0000\n",
            "Epoch 96/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2833.0205 - mae: 2833.0205 - mse: 33647220.0000 - val_loss: 3217.9170 - val_mae: 3217.9170 - val_mse: 39720932.0000\n",
            "Epoch 97/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2819.5459 - mae: 2819.5459 - mse: 33815260.0000 - val_loss: 3212.1743 - val_mae: 3212.1743 - val_mse: 39959772.0000\n",
            "Epoch 98/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2806.5549 - mae: 2806.5549 - mse: 33919324.0000 - val_loss: 3195.1917 - val_mae: 3195.1917 - val_mse: 40086964.0000\n",
            "Epoch 99/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2797.1379 - mae: 2797.1379 - mse: 34209444.0000 - val_loss: 3183.2827 - val_mae: 3183.2827 - val_mse: 40387348.0000\n",
            "Epoch 100/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2786.0552 - mae: 2786.0552 - mse: 34499216.0000 - val_loss: 3169.4077 - val_mae: 3169.4077 - val_mse: 40626800.0000\n",
            "Epoch 101/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2774.6345 - mae: 2774.6345 - mse: 34765424.0000 - val_loss: 3157.5725 - val_mae: 3157.5725 - val_mse: 40994652.0000\n",
            "Epoch 102/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2765.5579 - mae: 2765.5579 - mse: 34929744.0000 - val_loss: 3147.5408 - val_mae: 3147.5408 - val_mse: 41237380.0000\n",
            "Epoch 103/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2755.7188 - mae: 2755.7188 - mse: 35407292.0000 - val_loss: 3136.8440 - val_mae: 3136.8440 - val_mse: 41703148.0000\n",
            "Epoch 104/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2744.5593 - mae: 2744.5593 - mse: 35670800.0000 - val_loss: 3128.0110 - val_mae: 3128.0110 - val_mse: 41981812.0000\n",
            "Epoch 105/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2739.6970 - mae: 2739.6970 - mse: 36145176.0000 - val_loss: 3115.5908 - val_mae: 3115.5908 - val_mse: 42410860.0000\n",
            "Epoch 106/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2733.8086 - mae: 2733.8086 - mse: 36076044.0000 - val_loss: 3112.8767 - val_mae: 3112.8767 - val_mse: 42180932.0000\n",
            "Epoch 107/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2726.6458 - mae: 2726.6458 - mse: 36269736.0000 - val_loss: 3106.7576 - val_mae: 3106.7576 - val_mse: 42433780.0000\n",
            "Epoch 108/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2721.6721 - mae: 2721.6721 - mse: 36392760.0000 - val_loss: 3098.2827 - val_mae: 3098.2827 - val_mse: 42519664.0000\n",
            "Epoch 109/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2718.3066 - mae: 2718.3066 - mse: 36338208.0000 - val_loss: 3092.4402 - val_mae: 3092.4402 - val_mse: 42351072.0000\n",
            "Epoch 110/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2712.0046 - mae: 2712.0046 - mse: 36215872.0000 - val_loss: 3088.5818 - val_mae: 3088.5818 - val_mse: 42252804.0000\n",
            "Epoch 111/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2707.9187 - mae: 2707.9187 - mse: 36159492.0000 - val_loss: 3080.6506 - val_mae: 3080.6506 - val_mse: 42108780.0000\n",
            "Epoch 112/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2702.7080 - mae: 2702.7080 - mse: 36196172.0000 - val_loss: 3072.9500 - val_mae: 3072.9500 - val_mse: 42079308.0000\n",
            "Epoch 113/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2698.6814 - mae: 2698.6814 - mse: 36026048.0000 - val_loss: 3069.5793 - val_mae: 3069.5793 - val_mse: 41879488.0000\n",
            "Epoch 114/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2693.6768 - mae: 2693.6768 - mse: 35982868.0000 - val_loss: 3063.4023 - val_mae: 3063.4023 - val_mse: 41893688.0000\n",
            "Epoch 115/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2689.9641 - mae: 2689.9641 - mse: 35869252.0000 - val_loss: 3061.0015 - val_mae: 3061.0015 - val_mse: 41752080.0000\n",
            "Epoch 116/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2684.8767 - mae: 2684.8767 - mse: 35969368.0000 - val_loss: 3053.0293 - val_mae: 3053.0293 - val_mse: 41816944.0000\n",
            "Epoch 117/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2679.3994 - mae: 2679.3994 - mse: 35861772.0000 - val_loss: 3043.8364 - val_mae: 3043.8364 - val_mse: 41557316.0000\n",
            "Epoch 118/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2674.4185 - mae: 2674.4185 - mse: 35738228.0000 - val_loss: 3037.5181 - val_mae: 3037.5181 - val_mse: 41479796.0000\n",
            "Epoch 119/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2669.7935 - mae: 2669.7935 - mse: 35673028.0000 - val_loss: 3032.4082 - val_mae: 3032.4082 - val_mse: 41328152.0000\n",
            "Epoch 120/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2667.7275 - mae: 2667.7275 - mse: 35644580.0000 - val_loss: 3028.1211 - val_mae: 3028.1211 - val_mse: 41173508.0000\n",
            "Epoch 121/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2662.9431 - mae: 2662.9431 - mse: 35725048.0000 - val_loss: 3021.0674 - val_mae: 3021.0674 - val_mse: 41339392.0000\n",
            "Epoch 122/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2657.4514 - mae: 2657.4514 - mse: 35543604.0000 - val_loss: 3019.9675 - val_mae: 3019.9675 - val_mse: 41014132.0000\n",
            "Epoch 123/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2653.6721 - mae: 2653.6721 - mse: 35461332.0000 - val_loss: 3010.6604 - val_mae: 3010.6604 - val_mse: 40906388.0000\n",
            "Epoch 124/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2648.0845 - mae: 2648.0845 - mse: 35327080.0000 - val_loss: 3005.1890 - val_mae: 3005.1890 - val_mse: 40767924.0000\n",
            "Epoch 125/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2644.5847 - mae: 2644.5847 - mse: 35332200.0000 - val_loss: 2999.1729 - val_mae: 2999.1729 - val_mse: 40702976.0000\n",
            "Epoch 126/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2641.3662 - mae: 2641.3662 - mse: 35233860.0000 - val_loss: 2992.5420 - val_mae: 2992.5420 - val_mse: 40583784.0000\n",
            "Epoch 127/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2636.9258 - mae: 2636.9258 - mse: 35055076.0000 - val_loss: 2985.3916 - val_mae: 2985.3916 - val_mse: 40438292.0000\n",
            "Epoch 128/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2632.8101 - mae: 2632.8101 - mse: 35032460.0000 - val_loss: 2984.7234 - val_mae: 2984.7234 - val_mse: 40370760.0000\n",
            "Epoch 129/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2628.0747 - mae: 2628.0747 - mse: 34912868.0000 - val_loss: 2975.6816 - val_mae: 2975.6816 - val_mse: 40128476.0000\n",
            "Epoch 130/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2622.8274 - mae: 2622.8274 - mse: 34997696.0000 - val_loss: 2973.0759 - val_mae: 2973.0759 - val_mse: 40229592.0000\n",
            "Epoch 131/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2619.6924 - mae: 2619.6924 - mse: 34752860.0000 - val_loss: 2964.8618 - val_mae: 2964.8618 - val_mse: 39939228.0000\n",
            "Epoch 132/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2613.9004 - mae: 2613.9004 - mse: 34688796.0000 - val_loss: 2961.0295 - val_mae: 2961.0295 - val_mse: 39862908.0000\n",
            "Epoch 133/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2609.7236 - mae: 2609.7236 - mse: 34569088.0000 - val_loss: 2956.6179 - val_mae: 2956.6179 - val_mse: 39838992.0000\n",
            "Epoch 134/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2606.4539 - mae: 2606.4539 - mse: 34627392.0000 - val_loss: 2950.4282 - val_mae: 2950.4282 - val_mse: 39710096.0000\n",
            "Epoch 135/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2601.3855 - mae: 2601.3855 - mse: 34482912.0000 - val_loss: 2947.1782 - val_mae: 2947.1782 - val_mse: 39569636.0000\n",
            "Epoch 136/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2598.3130 - mae: 2598.3130 - mse: 34370296.0000 - val_loss: 2939.6204 - val_mae: 2939.6204 - val_mse: 39315028.0000\n",
            "Epoch 137/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2593.1851 - mae: 2593.1851 - mse: 34276576.0000 - val_loss: 2932.9021 - val_mae: 2932.9021 - val_mse: 39425048.0000\n",
            "Epoch 138/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2589.9478 - mae: 2589.9478 - mse: 34339552.0000 - val_loss: 2927.3306 - val_mae: 2927.3306 - val_mse: 39336212.0000\n",
            "Epoch 139/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2585.5178 - mae: 2585.5178 - mse: 34130368.0000 - val_loss: 2922.7988 - val_mae: 2922.7988 - val_mse: 39032344.0000\n",
            "Epoch 140/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2580.1460 - mae: 2580.1460 - mse: 34119968.0000 - val_loss: 2915.2876 - val_mae: 2915.2876 - val_mse: 39053744.0000\n",
            "Epoch 141/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2578.1460 - mae: 2578.1460 - mse: 33950520.0000 - val_loss: 2913.4607 - val_mae: 2913.4607 - val_mse: 38816520.0000\n",
            "Epoch 142/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2573.4111 - mae: 2573.4111 - mse: 33895780.0000 - val_loss: 2905.1829 - val_mae: 2905.1829 - val_mse: 38834952.0000\n",
            "Epoch 143/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2569.1680 - mae: 2569.1680 - mse: 33855304.0000 - val_loss: 2901.3850 - val_mae: 2901.3850 - val_mse: 38658776.0000\n",
            "Epoch 144/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2565.2778 - mae: 2565.2778 - mse: 33703716.0000 - val_loss: 2904.4648 - val_mae: 2904.4648 - val_mse: 38464836.0000\n",
            "Epoch 145/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2559.7029 - mae: 2559.7029 - mse: 33606368.0000 - val_loss: 2888.4910 - val_mae: 2888.4910 - val_mse: 38402180.0000\n",
            "Epoch 146/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2555.3066 - mae: 2555.3066 - mse: 33792948.0000 - val_loss: 2882.8926 - val_mae: 2882.8926 - val_mse: 38410244.0000\n",
            "Epoch 147/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2550.9021 - mae: 2550.9021 - mse: 33492478.0000 - val_loss: 2876.8291 - val_mae: 2876.8291 - val_mse: 38113356.0000\n",
            "Epoch 148/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2545.6189 - mae: 2545.6189 - mse: 33377922.0000 - val_loss: 2871.2783 - val_mae: 2871.2783 - val_mse: 37935516.0000\n",
            "Epoch 149/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2541.4021 - mae: 2541.4021 - mse: 33264946.0000 - val_loss: 2865.5227 - val_mae: 2865.5227 - val_mse: 37930528.0000\n",
            "Epoch 150/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2538.2935 - mae: 2538.2935 - mse: 33348036.0000 - val_loss: 2859.8513 - val_mae: 2859.8513 - val_mse: 37806152.0000\n",
            "Epoch 151/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2533.2842 - mae: 2533.2842 - mse: 33368980.0000 - val_loss: 2853.5581 - val_mae: 2853.5581 - val_mse: 37800876.0000\n",
            "Epoch 152/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2527.3259 - mae: 2527.3259 - mse: 33046768.0000 - val_loss: 2852.9294 - val_mae: 2852.9294 - val_mse: 37435912.0000\n",
            "Epoch 153/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2523.9314 - mae: 2523.9314 - mse: 32810534.0000 - val_loss: 2849.4302 - val_mae: 2849.4302 - val_mse: 37277620.0000\n",
            "Epoch 154/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2518.2219 - mae: 2518.2219 - mse: 32861748.0000 - val_loss: 2835.1841 - val_mae: 2835.1841 - val_mse: 37277460.0000\n",
            "Epoch 155/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2512.3660 - mae: 2512.3660 - mse: 32819808.0000 - val_loss: 2831.5239 - val_mae: 2831.5239 - val_mse: 37222476.0000\n",
            "Epoch 156/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2508.1741 - mae: 2508.1741 - mse: 32755638.0000 - val_loss: 2824.1509 - val_mae: 2824.1509 - val_mse: 37012544.0000\n",
            "Epoch 157/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2502.6565 - mae: 2502.6565 - mse: 32613462.0000 - val_loss: 2816.7502 - val_mae: 2816.7502 - val_mse: 36920716.0000\n",
            "Epoch 158/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2499.5808 - mae: 2499.5808 - mse: 32488276.0000 - val_loss: 2817.1841 - val_mae: 2817.1841 - val_mse: 36756940.0000\n",
            "Epoch 159/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2495.1414 - mae: 2495.1414 - mse: 32503738.0000 - val_loss: 2805.5627 - val_mae: 2805.5627 - val_mse: 36618924.0000\n",
            "Epoch 160/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2489.1206 - mae: 2489.1206 - mse: 32287288.0000 - val_loss: 2801.0042 - val_mae: 2801.0042 - val_mse: 36505020.0000\n",
            "Epoch 161/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2488.1082 - mae: 2488.1082 - mse: 32214970.0000 - val_loss: 2791.9675 - val_mae: 2791.9675 - val_mse: 36321112.0000\n",
            "Epoch 162/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2482.5562 - mae: 2482.5562 - mse: 32246908.0000 - val_loss: 2792.4048 - val_mae: 2792.4048 - val_mse: 36290692.0000\n",
            "Epoch 163/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2476.1863 - mae: 2476.1863 - mse: 32167176.0000 - val_loss: 2783.0361 - val_mae: 2783.0361 - val_mse: 36154108.0000\n",
            "Epoch 164/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2471.3525 - mae: 2471.3525 - mse: 32033588.0000 - val_loss: 2778.8945 - val_mae: 2778.8945 - val_mse: 36088636.0000\n",
            "Epoch 165/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2467.6089 - mae: 2467.6089 - mse: 31983192.0000 - val_loss: 2772.1711 - val_mae: 2772.1711 - val_mse: 35967716.0000\n",
            "Epoch 166/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2462.4180 - mae: 2462.4180 - mse: 31937986.0000 - val_loss: 2768.5178 - val_mae: 2768.5178 - val_mse: 35843800.0000\n",
            "Epoch 167/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2458.5823 - mae: 2458.5823 - mse: 31785926.0000 - val_loss: 2763.1746 - val_mae: 2763.1746 - val_mse: 35685688.0000\n",
            "Epoch 168/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2454.9158 - mae: 2454.9158 - mse: 31688790.0000 - val_loss: 2758.6077 - val_mae: 2758.6077 - val_mse: 35553900.0000\n",
            "Epoch 169/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2450.0842 - mae: 2450.0842 - mse: 31542554.0000 - val_loss: 2751.1799 - val_mae: 2751.1799 - val_mse: 35457000.0000\n",
            "Epoch 170/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2446.1477 - mae: 2446.1477 - mse: 31579088.0000 - val_loss: 2747.8938 - val_mae: 2747.8938 - val_mse: 35398224.0000\n",
            "Epoch 171/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2442.0513 - mae: 2442.0513 - mse: 31401216.0000 - val_loss: 2741.7544 - val_mae: 2741.7544 - val_mse: 35217660.0000\n",
            "Epoch 172/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2437.0034 - mae: 2437.0034 - mse: 31318648.0000 - val_loss: 2737.5828 - val_mae: 2737.5828 - val_mse: 35148916.0000\n",
            "Epoch 173/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2436.0339 - mae: 2436.0339 - mse: 31328194.0000 - val_loss: 2733.6211 - val_mae: 2733.6211 - val_mse: 35039832.0000\n",
            "Epoch 174/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2429.9619 - mae: 2429.9619 - mse: 31227676.0000 - val_loss: 2726.0913 - val_mae: 2726.0913 - val_mse: 34996984.0000\n",
            "Epoch 175/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2426.3665 - mae: 2426.3665 - mse: 31054402.0000 - val_loss: 2722.2268 - val_mae: 2722.2268 - val_mse: 34732360.0000\n",
            "Epoch 176/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2419.9551 - mae: 2419.9551 - mse: 30985426.0000 - val_loss: 2717.3943 - val_mae: 2717.3943 - val_mse: 34687348.0000\n",
            "Epoch 177/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2417.4558 - mae: 2417.4558 - mse: 30917220.0000 - val_loss: 2712.2495 - val_mae: 2712.2495 - val_mse: 34488664.0000\n",
            "Epoch 178/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2414.6204 - mae: 2414.6204 - mse: 31038612.0000 - val_loss: 2708.4241 - val_mae: 2708.4241 - val_mse: 34563680.0000\n",
            "Epoch 179/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2410.6626 - mae: 2410.6626 - mse: 30641764.0000 - val_loss: 2706.2725 - val_mae: 2706.2725 - val_mse: 34240724.0000\n",
            "Epoch 180/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2404.5994 - mae: 2404.5994 - mse: 30643166.0000 - val_loss: 2698.8938 - val_mae: 2698.8938 - val_mse: 34200116.0000\n",
            "Epoch 181/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2401.4912 - mae: 2401.4912 - mse: 30496112.0000 - val_loss: 2697.8574 - val_mae: 2697.8574 - val_mse: 34010224.0000\n",
            "Epoch 182/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2397.3396 - mae: 2397.3396 - mse: 30477012.0000 - val_loss: 2687.0793 - val_mae: 2687.0793 - val_mse: 33847748.0000\n",
            "Epoch 183/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2390.5396 - mae: 2390.5396 - mse: 30321776.0000 - val_loss: 2684.2590 - val_mae: 2684.2590 - val_mse: 33843256.0000\n",
            "Epoch 184/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2388.6833 - mae: 2388.6833 - mse: 30465150.0000 - val_loss: 2679.3203 - val_mae: 2679.3203 - val_mse: 33755724.0000\n",
            "Epoch 185/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2383.6931 - mae: 2383.6931 - mse: 30102000.0000 - val_loss: 2674.4580 - val_mae: 2674.4580 - val_mse: 33429396.0000\n",
            "Epoch 186/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2379.4375 - mae: 2379.4375 - mse: 30018726.0000 - val_loss: 2669.0342 - val_mae: 2669.0342 - val_mse: 33431962.0000\n",
            "Epoch 187/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2375.9966 - mae: 2375.9966 - mse: 29875640.0000 - val_loss: 2663.7932 - val_mae: 2663.7932 - val_mse: 33185904.0000\n",
            "Epoch 188/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2370.6982 - mae: 2370.6982 - mse: 29884238.0000 - val_loss: 2659.9644 - val_mae: 2659.9644 - val_mse: 33160666.0000\n",
            "Epoch 189/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2366.2817 - mae: 2366.2817 - mse: 29706886.0000 - val_loss: 2661.2476 - val_mae: 2661.2476 - val_mse: 33039632.0000\n",
            "Epoch 190/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2363.8533 - mae: 2363.8533 - mse: 29827726.0000 - val_loss: 2651.6411 - val_mae: 2651.6411 - val_mse: 32996022.0000\n",
            "Epoch 191/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2357.8655 - mae: 2357.8655 - mse: 29515500.0000 - val_loss: 2649.0879 - val_mae: 2649.0879 - val_mse: 32709830.0000\n",
            "Epoch 192/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2354.1843 - mae: 2354.1843 - mse: 29445546.0000 - val_loss: 2640.8867 - val_mae: 2640.8867 - val_mse: 32547650.0000\n",
            "Epoch 193/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2349.9358 - mae: 2349.9358 - mse: 29411174.0000 - val_loss: 2639.6343 - val_mae: 2639.6343 - val_mse: 32594076.0000\n",
            "Epoch 194/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2346.4666 - mae: 2346.4666 - mse: 29282732.0000 - val_loss: 2637.5107 - val_mae: 2637.5107 - val_mse: 32373216.0000\n",
            "Epoch 195/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2340.9766 - mae: 2340.9766 - mse: 29187392.0000 - val_loss: 2628.0652 - val_mae: 2628.0652 - val_mse: 32213764.0000\n",
            "Epoch 196/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2338.6379 - mae: 2338.6379 - mse: 29182590.0000 - val_loss: 2622.4688 - val_mae: 2622.4688 - val_mse: 32308344.0000\n",
            "Epoch 197/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2332.7869 - mae: 2332.7869 - mse: 28955280.0000 - val_loss: 2619.8105 - val_mae: 2619.8105 - val_mse: 31897976.0000\n",
            "Epoch 198/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2329.3518 - mae: 2329.3518 - mse: 28762212.0000 - val_loss: 2616.0444 - val_mae: 2616.0444 - val_mse: 31816462.0000\n",
            "Epoch 199/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2323.7744 - mae: 2323.7744 - mse: 28728262.0000 - val_loss: 2609.8928 - val_mae: 2609.8928 - val_mse: 31720628.0000\n",
            "Epoch 200/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2319.3853 - mae: 2319.3853 - mse: 28701760.0000 - val_loss: 2601.5994 - val_mae: 2601.5994 - val_mse: 31647600.0000\n",
            "Epoch 201/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2315.6147 - mae: 2315.6147 - mse: 28574998.0000 - val_loss: 2599.1602 - val_mae: 2599.1602 - val_mse: 31363862.0000\n",
            "Epoch 202/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2310.2419 - mae: 2310.2419 - mse: 28488904.0000 - val_loss: 2591.6665 - val_mae: 2591.6665 - val_mse: 31379514.0000\n",
            "Epoch 203/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2307.2883 - mae: 2307.2883 - mse: 28367142.0000 - val_loss: 2588.6523 - val_mae: 2588.6523 - val_mse: 31145740.0000\n",
            "Epoch 204/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2303.2959 - mae: 2303.2959 - mse: 28220204.0000 - val_loss: 2580.1934 - val_mae: 2580.1934 - val_mse: 31064810.0000\n",
            "Epoch 205/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2297.6016 - mae: 2297.6016 - mse: 28234458.0000 - val_loss: 2579.3391 - val_mae: 2579.3391 - val_mse: 30949702.0000\n",
            "Epoch 206/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2294.5166 - mae: 2294.5166 - mse: 28054408.0000 - val_loss: 2575.6338 - val_mae: 2575.6338 - val_mse: 30790944.0000\n",
            "Epoch 207/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2289.6890 - mae: 2289.6890 - mse: 27980828.0000 - val_loss: 2566.2559 - val_mae: 2566.2559 - val_mse: 30656156.0000\n",
            "Epoch 208/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2286.0776 - mae: 2286.0776 - mse: 27847802.0000 - val_loss: 2562.3174 - val_mae: 2562.3174 - val_mse: 30500764.0000\n",
            "Epoch 209/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2281.2546 - mae: 2281.2546 - mse: 27817608.0000 - val_loss: 2558.9492 - val_mae: 2558.9492 - val_mse: 30527950.0000\n",
            "Epoch 210/600\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 2276.9734 - mae: 2276.9734 - mse: 27761062.0000 - val_loss: 2553.6765 - val_mae: 2553.6765 - val_mse: 30368496.0000\n",
            "Epoch 211/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2273.6814 - mae: 2273.6814 - mse: 27606462.0000 - val_loss: 2547.8049 - val_mae: 2547.8049 - val_mse: 30137722.0000\n",
            "Epoch 212/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2268.9150 - mae: 2268.9150 - mse: 27450828.0000 - val_loss: 2545.0012 - val_mae: 2545.0012 - val_mse: 30070466.0000\n",
            "Epoch 213/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2265.3516 - mae: 2265.3516 - mse: 27437394.0000 - val_loss: 2538.5706 - val_mae: 2538.5706 - val_mse: 29910664.0000\n",
            "Epoch 214/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2260.5505 - mae: 2260.5505 - mse: 27271060.0000 - val_loss: 2533.1350 - val_mae: 2533.1350 - val_mse: 29759528.0000\n",
            "Epoch 215/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2256.0598 - mae: 2256.0598 - mse: 27218786.0000 - val_loss: 2529.5933 - val_mae: 2529.5933 - val_mse: 29667972.0000\n",
            "Epoch 216/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2253.3657 - mae: 2253.3657 - mse: 27065170.0000 - val_loss: 2523.8049 - val_mae: 2523.8049 - val_mse: 29537338.0000\n",
            "Epoch 217/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2250.4683 - mae: 2250.4683 - mse: 27128182.0000 - val_loss: 2520.4944 - val_mae: 2520.4944 - val_mse: 29478998.0000\n",
            "Epoch 218/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2246.1313 - mae: 2246.1313 - mse: 26846704.0000 - val_loss: 2515.6724 - val_mae: 2515.6724 - val_mse: 29214782.0000\n",
            "Epoch 219/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2240.5198 - mae: 2240.5198 - mse: 26850626.0000 - val_loss: 2511.0024 - val_mae: 2511.0024 - val_mse: 29271470.0000\n",
            "Epoch 220/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2236.3708 - mae: 2236.3708 - mse: 26694522.0000 - val_loss: 2505.1729 - val_mae: 2505.1729 - val_mse: 29009496.0000\n",
            "Epoch 221/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2230.3689 - mae: 2230.3689 - mse: 26610112.0000 - val_loss: 2499.0857 - val_mae: 2499.0857 - val_mse: 28976966.0000\n",
            "Epoch 222/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2227.2065 - mae: 2227.2065 - mse: 26498048.0000 - val_loss: 2495.7971 - val_mae: 2495.7971 - val_mse: 28764564.0000\n",
            "Epoch 223/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2221.5518 - mae: 2221.5518 - mse: 26389934.0000 - val_loss: 2488.8601 - val_mae: 2488.8601 - val_mse: 28663842.0000\n",
            "Epoch 224/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2218.1650 - mae: 2218.1650 - mse: 26361700.0000 - val_loss: 2483.8938 - val_mae: 2483.8938 - val_mse: 28621694.0000\n",
            "Epoch 225/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2214.3770 - mae: 2214.3770 - mse: 26248440.0000 - val_loss: 2480.7852 - val_mae: 2480.7852 - val_mse: 28446344.0000\n",
            "Epoch 226/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2209.7019 - mae: 2209.7019 - mse: 26204600.0000 - val_loss: 2474.8164 - val_mae: 2474.8164 - val_mse: 28393012.0000\n",
            "Epoch 227/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2206.3599 - mae: 2206.3599 - mse: 26060850.0000 - val_loss: 2468.5732 - val_mae: 2468.5732 - val_mse: 28111254.0000\n",
            "Epoch 228/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2200.7891 - mae: 2200.7891 - mse: 25983260.0000 - val_loss: 2465.8093 - val_mae: 2465.8093 - val_mse: 28082516.0000\n",
            "Epoch 229/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2196.0823 - mae: 2196.0823 - mse: 25907748.0000 - val_loss: 2455.7595 - val_mae: 2455.7595 - val_mse: 27977194.0000\n",
            "Epoch 230/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2193.9443 - mae: 2193.9443 - mse: 25795528.0000 - val_loss: 2454.5369 - val_mae: 2454.5369 - val_mse: 27853560.0000\n",
            "Epoch 231/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2187.2539 - mae: 2187.2539 - mse: 25664754.0000 - val_loss: 2449.4287 - val_mae: 2449.4287 - val_mse: 27653738.0000\n",
            "Epoch 232/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2183.6917 - mae: 2183.6917 - mse: 25596394.0000 - val_loss: 2442.9861 - val_mae: 2442.9861 - val_mse: 27581932.0000\n",
            "Epoch 233/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2177.6492 - mae: 2177.6492 - mse: 25512304.0000 - val_loss: 2440.0532 - val_mae: 2440.0532 - val_mse: 27471470.0000\n",
            "Epoch 234/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2174.4719 - mae: 2174.4719 - mse: 25419032.0000 - val_loss: 2434.4543 - val_mae: 2434.4543 - val_mse: 27302098.0000\n",
            "Epoch 235/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2168.8459 - mae: 2168.8459 - mse: 25278342.0000 - val_loss: 2426.2043 - val_mae: 2426.2043 - val_mse: 27253764.0000\n",
            "Epoch 236/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2163.0227 - mae: 2163.0227 - mse: 25231582.0000 - val_loss: 2418.5613 - val_mae: 2418.5613 - val_mse: 27126698.0000\n",
            "Epoch 237/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2159.2114 - mae: 2159.2114 - mse: 25157148.0000 - val_loss: 2412.0938 - val_mae: 2412.0938 - val_mse: 26981774.0000\n",
            "Epoch 238/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2154.0344 - mae: 2154.0344 - mse: 25037286.0000 - val_loss: 2407.1150 - val_mae: 2407.1150 - val_mse: 26870138.0000\n",
            "Epoch 239/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2150.6375 - mae: 2150.6375 - mse: 24977942.0000 - val_loss: 2401.0327 - val_mae: 2401.0327 - val_mse: 26800212.0000\n",
            "Epoch 240/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2145.9512 - mae: 2145.9512 - mse: 24895398.0000 - val_loss: 2398.6421 - val_mae: 2398.6421 - val_mse: 26718088.0000\n",
            "Epoch 241/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2141.9905 - mae: 2141.9905 - mse: 24813480.0000 - val_loss: 2392.0857 - val_mae: 2392.0857 - val_mse: 26546086.0000\n",
            "Epoch 242/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2137.2312 - mae: 2137.2312 - mse: 24741660.0000 - val_loss: 2390.4543 - val_mae: 2390.4543 - val_mse: 26442378.0000\n",
            "Epoch 243/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2135.0547 - mae: 2135.0547 - mse: 24704986.0000 - val_loss: 2379.4114 - val_mae: 2379.4114 - val_mse: 26428522.0000\n",
            "Epoch 244/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2129.1089 - mae: 2129.1089 - mse: 24580758.0000 - val_loss: 2377.3171 - val_mae: 2377.3171 - val_mse: 26272158.0000\n",
            "Epoch 245/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2124.3857 - mae: 2124.3857 - mse: 24516952.0000 - val_loss: 2370.8870 - val_mae: 2370.8870 - val_mse: 26141964.0000\n",
            "Epoch 246/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2120.0474 - mae: 2120.0474 - mse: 24447734.0000 - val_loss: 2364.6094 - val_mae: 2364.6094 - val_mse: 26059256.0000\n",
            "Epoch 247/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2114.9141 - mae: 2114.9141 - mse: 24350170.0000 - val_loss: 2357.3696 - val_mae: 2357.3694 - val_mse: 25982566.0000\n",
            "Epoch 248/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2111.8018 - mae: 2111.8018 - mse: 24295750.0000 - val_loss: 2351.3843 - val_mae: 2351.3840 - val_mse: 25845220.0000\n",
            "Epoch 249/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2108.3513 - mae: 2108.3513 - mse: 24157110.0000 - val_loss: 2353.8562 - val_mae: 2353.8562 - val_mse: 25722866.0000\n",
            "Epoch 250/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2102.4744 - mae: 2102.4744 - mse: 24104372.0000 - val_loss: 2342.5437 - val_mae: 2342.5437 - val_mse: 25644386.0000\n",
            "Epoch 251/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2097.6807 - mae: 2097.6807 - mse: 24045202.0000 - val_loss: 2334.4722 - val_mae: 2334.4722 - val_mse: 25517710.0000\n",
            "Epoch 252/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2094.7698 - mae: 2094.7698 - mse: 23946760.0000 - val_loss: 2331.1929 - val_mae: 2331.1929 - val_mse: 25390736.0000\n",
            "Epoch 253/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2088.5610 - mae: 2088.5610 - mse: 23830384.0000 - val_loss: 2324.4006 - val_mae: 2324.4006 - val_mse: 25326356.0000\n",
            "Epoch 254/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2085.6216 - mae: 2085.6216 - mse: 23825546.0000 - val_loss: 2317.7078 - val_mae: 2317.7078 - val_mse: 25244888.0000\n",
            "Epoch 255/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2080.2910 - mae: 2080.2910 - mse: 23755554.0000 - val_loss: 2312.5566 - val_mae: 2312.5566 - val_mse: 25147042.0000\n",
            "Epoch 256/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2075.6917 - mae: 2075.6917 - mse: 23678752.0000 - val_loss: 2307.3516 - val_mae: 2307.3516 - val_mse: 25079012.0000\n",
            "Epoch 257/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2073.6665 - mae: 2073.6665 - mse: 23562288.0000 - val_loss: 2304.1018 - val_mae: 2304.1018 - val_mse: 24934086.0000\n",
            "Epoch 258/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2066.5286 - mae: 2066.5286 - mse: 23531164.0000 - val_loss: 2296.9438 - val_mae: 2296.9438 - val_mse: 24874032.0000\n",
            "Epoch 259/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2061.9841 - mae: 2061.9841 - mse: 23462766.0000 - val_loss: 2292.6621 - val_mae: 2292.6621 - val_mse: 24744678.0000\n",
            "Epoch 260/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2059.9172 - mae: 2059.9172 - mse: 23416876.0000 - val_loss: 2284.0154 - val_mae: 2284.0154 - val_mse: 24707940.0000\n",
            "Epoch 261/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2054.1516 - mae: 2054.1516 - mse: 23341846.0000 - val_loss: 2281.6279 - val_mae: 2281.6279 - val_mse: 24588178.0000\n",
            "Epoch 262/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2050.9641 - mae: 2050.9641 - mse: 23330950.0000 - val_loss: 2271.3240 - val_mae: 2271.3240 - val_mse: 24545258.0000\n",
            "Epoch 263/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2045.1176 - mae: 2045.1176 - mse: 23190886.0000 - val_loss: 2267.6565 - val_mae: 2267.6565 - val_mse: 24419168.0000\n",
            "Epoch 264/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2041.5299 - mae: 2041.5299 - mse: 23147066.0000 - val_loss: 2259.4355 - val_mae: 2259.4355 - val_mse: 24364862.0000\n",
            "Epoch 265/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2038.3818 - mae: 2038.3818 - mse: 23082548.0000 - val_loss: 2253.3440 - val_mae: 2253.3440 - val_mse: 24263360.0000\n",
            "Epoch 266/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2033.7173 - mae: 2033.7173 - mse: 23022258.0000 - val_loss: 2248.3787 - val_mae: 2248.3787 - val_mse: 24145504.0000\n",
            "Epoch 267/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2027.4486 - mae: 2027.4486 - mse: 22950774.0000 - val_loss: 2241.5586 - val_mae: 2241.5586 - val_mse: 24126582.0000\n",
            "Epoch 268/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2024.3685 - mae: 2024.3685 - mse: 22910708.0000 - val_loss: 2235.8157 - val_mae: 2235.8157 - val_mse: 24040256.0000\n",
            "Epoch 269/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2018.7552 - mae: 2018.7552 - mse: 22846700.0000 - val_loss: 2230.8303 - val_mae: 2230.8303 - val_mse: 23976934.0000\n",
            "Epoch 270/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2015.2777 - mae: 2015.2777 - mse: 22782972.0000 - val_loss: 2223.7932 - val_mae: 2223.7932 - val_mse: 23865928.0000\n",
            "Epoch 271/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2010.6594 - mae: 2010.6594 - mse: 22734692.0000 - val_loss: 2217.8784 - val_mae: 2217.8784 - val_mse: 23817728.0000\n",
            "Epoch 272/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2007.7915 - mae: 2007.7915 - mse: 22650244.0000 - val_loss: 2214.2644 - val_mae: 2214.2644 - val_mse: 23725142.0000\n",
            "Epoch 273/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2002.8090 - mae: 2002.8090 - mse: 22574360.0000 - val_loss: 2206.0063 - val_mae: 2206.0063 - val_mse: 23646766.0000\n",
            "Epoch 274/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1996.8110 - mae: 1996.8110 - mse: 22540210.0000 - val_loss: 2204.2056 - val_mae: 2204.2056 - val_mse: 23516050.0000\n",
            "Epoch 275/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1993.7665 - mae: 1993.7665 - mse: 22479082.0000 - val_loss: 2200.2517 - val_mae: 2200.2517 - val_mse: 23459994.0000\n",
            "Epoch 276/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1989.0829 - mae: 1989.0829 - mse: 22449726.0000 - val_loss: 2189.9502 - val_mae: 2189.9502 - val_mse: 23397816.0000\n",
            "Epoch 277/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1984.0565 - mae: 1984.0565 - mse: 22389210.0000 - val_loss: 2186.1045 - val_mae: 2186.1045 - val_mse: 23306312.0000\n",
            "Epoch 278/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1979.0699 - mae: 1979.0699 - mse: 22330974.0000 - val_loss: 2183.4224 - val_mae: 2183.4224 - val_mse: 23242562.0000\n",
            "Epoch 279/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1974.8585 - mae: 1974.8585 - mse: 22296392.0000 - val_loss: 2172.8679 - val_mae: 2172.8679 - val_mse: 23185030.0000\n",
            "Epoch 280/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1969.0027 - mae: 1969.0027 - mse: 22250164.0000 - val_loss: 2166.1370 - val_mae: 2166.1370 - val_mse: 23201660.0000\n",
            "Epoch 281/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1967.4448 - mae: 1967.4448 - mse: 22195224.0000 - val_loss: 2160.9163 - val_mae: 2160.9163 - val_mse: 23073234.0000\n",
            "Epoch 282/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1961.0233 - mae: 1961.0233 - mse: 22136612.0000 - val_loss: 2153.9470 - val_mae: 2153.9470 - val_mse: 22998056.0000\n",
            "Epoch 283/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1958.0558 - mae: 1958.0558 - mse: 22097434.0000 - val_loss: 2147.5029 - val_mae: 2147.5029 - val_mse: 22933682.0000\n",
            "Epoch 284/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1951.7100 - mae: 1951.7100 - mse: 22034674.0000 - val_loss: 2139.4309 - val_mae: 2139.4309 - val_mse: 22899956.0000\n",
            "Epoch 285/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1947.3816 - mae: 1947.3816 - mse: 21986806.0000 - val_loss: 2133.3374 - val_mae: 2133.3374 - val_mse: 22860170.0000\n",
            "Epoch 286/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1943.1890 - mae: 1943.1890 - mse: 21960114.0000 - val_loss: 2129.7534 - val_mae: 2129.7534 - val_mse: 22813294.0000\n",
            "Epoch 287/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1937.6423 - mae: 1937.6423 - mse: 21911092.0000 - val_loss: 2121.1721 - val_mae: 2121.1721 - val_mse: 22734094.0000\n",
            "Epoch 288/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1932.4994 - mae: 1932.4994 - mse: 21864078.0000 - val_loss: 2116.0452 - val_mae: 2116.0452 - val_mse: 22678866.0000\n",
            "Epoch 289/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1928.5325 - mae: 1928.5325 - mse: 21828860.0000 - val_loss: 2110.7407 - val_mae: 2110.7407 - val_mse: 22593746.0000\n",
            "Epoch 290/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1922.6182 - mae: 1922.6182 - mse: 21799846.0000 - val_loss: 2103.5823 - val_mae: 2103.5823 - val_mse: 22543398.0000\n",
            "Epoch 291/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1919.1554 - mae: 1919.1554 - mse: 21762770.0000 - val_loss: 2099.6445 - val_mae: 2099.6445 - val_mse: 22504762.0000\n",
            "Epoch 292/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1913.3269 - mae: 1913.3269 - mse: 21719998.0000 - val_loss: 2092.6052 - val_mae: 2092.6052 - val_mse: 22441794.0000\n",
            "Epoch 293/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1911.5270 - mae: 1911.5270 - mse: 21659192.0000 - val_loss: 2092.1938 - val_mae: 2092.1938 - val_mse: 22362502.0000\n",
            "Epoch 294/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1904.9159 - mae: 1904.9159 - mse: 21633220.0000 - val_loss: 2080.2312 - val_mae: 2080.2312 - val_mse: 22351538.0000\n",
            "Epoch 295/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1900.5479 - mae: 1900.5479 - mse: 21607510.0000 - val_loss: 2075.1313 - val_mae: 2075.1313 - val_mse: 22336594.0000\n",
            "Epoch 296/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1897.6379 - mae: 1897.6379 - mse: 21581004.0000 - val_loss: 2069.0330 - val_mae: 2069.0330 - val_mse: 22260822.0000\n",
            "Epoch 297/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1891.9762 - mae: 1891.9762 - mse: 21542432.0000 - val_loss: 2065.7063 - val_mae: 2065.7063 - val_mse: 22206900.0000\n",
            "Epoch 298/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1889.3892 - mae: 1889.3892 - mse: 21497112.0000 - val_loss: 2058.7341 - val_mae: 2058.7341 - val_mse: 22172110.0000\n",
            "Epoch 299/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1885.3733 - mae: 1885.3733 - mse: 21487636.0000 - val_loss: 2057.9600 - val_mae: 2057.9600 - val_mse: 22091250.0000\n",
            "Epoch 300/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1883.1371 - mae: 1883.1371 - mse: 21458488.0000 - val_loss: 2053.8215 - val_mae: 2053.8215 - val_mse: 22026730.0000\n",
            "Epoch 301/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1875.5844 - mae: 1875.5844 - mse: 21416680.0000 - val_loss: 2044.5245 - val_mae: 2044.5245 - val_mse: 22036298.0000\n",
            "Epoch 302/600\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1872.8433 - mae: 1872.8433 - mse: 21357680.0000 - val_loss: 2040.4653 - val_mae: 2040.4653 - val_mse: 22019808.0000\n",
            "Epoch 303/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1868.1650 - mae: 1868.1650 - mse: 21382840.0000 - val_loss: 2035.9189 - val_mae: 2035.9189 - val_mse: 21941384.0000\n",
            "Epoch 304/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1865.5665 - mae: 1865.5665 - mse: 21354714.0000 - val_loss: 2031.0609 - val_mae: 2031.0609 - val_mse: 21922836.0000\n",
            "Epoch 305/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1859.3960 - mae: 1859.3960 - mse: 21307286.0000 - val_loss: 2026.2399 - val_mae: 2026.2399 - val_mse: 21849230.0000\n",
            "Epoch 306/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1854.5729 - mae: 1854.5729 - mse: 21291652.0000 - val_loss: 2021.6104 - val_mae: 2021.6104 - val_mse: 21849198.0000\n",
            "Epoch 307/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1850.0314 - mae: 1850.0314 - mse: 21258036.0000 - val_loss: 2018.5642 - val_mae: 2018.5642 - val_mse: 21778360.0000\n",
            "Epoch 308/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1846.7485 - mae: 1846.7485 - mse: 21234380.0000 - val_loss: 2012.4165 - val_mae: 2012.4165 - val_mse: 21772324.0000\n",
            "Epoch 309/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1844.3481 - mae: 1844.3481 - mse: 21203226.0000 - val_loss: 2007.2419 - val_mae: 2007.2419 - val_mse: 21759416.0000\n",
            "Epoch 310/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1839.7665 - mae: 1839.7665 - mse: 21190046.0000 - val_loss: 2001.9325 - val_mae: 2001.9325 - val_mse: 21674324.0000\n",
            "Epoch 311/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1834.6011 - mae: 1834.6011 - mse: 21169208.0000 - val_loss: 1997.6558 - val_mae: 1997.6558 - val_mse: 21658480.0000\n",
            "Epoch 312/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1831.5847 - mae: 1831.5847 - mse: 21133716.0000 - val_loss: 1994.8058 - val_mae: 1994.8058 - val_mse: 21578736.0000\n",
            "Epoch 313/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1827.2693 - mae: 1827.2693 - mse: 21115244.0000 - val_loss: 1988.3560 - val_mae: 1988.3560 - val_mse: 21527514.0000\n",
            "Epoch 314/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1824.4502 - mae: 1824.4502 - mse: 21078430.0000 - val_loss: 1984.3073 - val_mae: 1984.3073 - val_mse: 21521448.0000\n",
            "Epoch 315/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1820.0206 - mae: 1820.0206 - mse: 21079274.0000 - val_loss: 1982.0455 - val_mae: 1982.0455 - val_mse: 21530498.0000\n",
            "Epoch 316/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1819.4863 - mae: 1819.4863 - mse: 21068364.0000 - val_loss: 1974.7527 - val_mae: 1974.7527 - val_mse: 21419224.0000\n",
            "Epoch 317/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1815.1780 - mae: 1815.1780 - mse: 21017526.0000 - val_loss: 1970.2472 - val_mae: 1970.2472 - val_mse: 21360772.0000\n",
            "Epoch 318/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1809.0906 - mae: 1809.0906 - mse: 21018966.0000 - val_loss: 1966.7421 - val_mae: 1966.7421 - val_mse: 21395642.0000\n",
            "Epoch 319/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1806.5765 - mae: 1806.5765 - mse: 20979386.0000 - val_loss: 1963.9810 - val_mae: 1963.9810 - val_mse: 21376550.0000\n",
            "Epoch 320/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1802.6746 - mae: 1802.6746 - mse: 20961314.0000 - val_loss: 1958.9637 - val_mae: 1958.9637 - val_mse: 21315890.0000\n",
            "Epoch 321/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1798.2208 - mae: 1798.2208 - mse: 20964132.0000 - val_loss: 1953.6681 - val_mae: 1953.6681 - val_mse: 21269406.0000\n",
            "Epoch 322/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1796.5411 - mae: 1796.5411 - mse: 20917996.0000 - val_loss: 1950.4358 - val_mae: 1950.4358 - val_mse: 21252628.0000\n",
            "Epoch 323/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1792.8472 - mae: 1792.8472 - mse: 20926234.0000 - val_loss: 1945.2207 - val_mae: 1945.2207 - val_mse: 21170948.0000\n",
            "Epoch 324/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1790.5172 - mae: 1790.5172 - mse: 20888032.0000 - val_loss: 1940.4207 - val_mae: 1940.4207 - val_mse: 21177580.0000\n",
            "Epoch 325/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1789.2715 - mae: 1789.2715 - mse: 20902294.0000 - val_loss: 1937.5067 - val_mae: 1937.5067 - val_mse: 21136238.0000\n",
            "Epoch 326/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1782.0486 - mae: 1782.0486 - mse: 20851592.0000 - val_loss: 1933.2402 - val_mae: 1933.2402 - val_mse: 21131336.0000\n",
            "Epoch 327/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1778.6876 - mae: 1778.6876 - mse: 20843972.0000 - val_loss: 1931.8933 - val_mae: 1931.8933 - val_mse: 21099988.0000\n",
            "Epoch 328/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1776.1259 - mae: 1776.1259 - mse: 20830778.0000 - val_loss: 1925.7360 - val_mae: 1925.7360 - val_mse: 21014294.0000\n",
            "Epoch 329/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1772.3108 - mae: 1772.3108 - mse: 20804586.0000 - val_loss: 1922.3291 - val_mae: 1922.3291 - val_mse: 20989102.0000\n",
            "Epoch 330/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1769.5548 - mae: 1769.5548 - mse: 20767114.0000 - val_loss: 1918.5514 - val_mae: 1918.5514 - val_mse: 20966042.0000\n",
            "Epoch 331/600\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1768.6531 - mae: 1768.6531 - mse: 20770418.0000 - val_loss: 1913.8737 - val_mae: 1913.8737 - val_mse: 20942566.0000\n",
            "Epoch 332/600\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1763.9675 - mae: 1763.9675 - mse: 20776056.0000 - val_loss: 1911.2982 - val_mae: 1911.2982 - val_mse: 20966446.0000\n",
            "Epoch 333/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1762.0758 - mae: 1762.0758 - mse: 20761126.0000 - val_loss: 1905.9456 - val_mae: 1905.9456 - val_mse: 20911364.0000\n",
            "Epoch 334/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1756.4783 - mae: 1756.4783 - mse: 20715284.0000 - val_loss: 1899.3833 - val_mae: 1899.3833 - val_mse: 20837716.0000\n",
            "Epoch 335/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1755.2657 - mae: 1755.2657 - mse: 20695624.0000 - val_loss: 1897.4362 - val_mae: 1897.4362 - val_mse: 20864416.0000\n",
            "Epoch 336/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1755.1223 - mae: 1755.1223 - mse: 20726414.0000 - val_loss: 1896.1798 - val_mae: 1896.1798 - val_mse: 20854490.0000\n",
            "Epoch 337/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1749.6206 - mae: 1749.6206 - mse: 20688888.0000 - val_loss: 1890.3542 - val_mae: 1890.3542 - val_mse: 20759220.0000\n",
            "Epoch 338/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1747.4224 - mae: 1747.4224 - mse: 20661070.0000 - val_loss: 1886.3572 - val_mae: 1886.3572 - val_mse: 20765230.0000\n",
            "Epoch 339/600\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1742.6102 - mae: 1742.6102 - mse: 20646952.0000 - val_loss: 1884.5134 - val_mae: 1884.5134 - val_mse: 20801422.0000\n",
            "Epoch 340/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1742.3269 - mae: 1742.3269 - mse: 20669404.0000 - val_loss: 1879.8589 - val_mae: 1879.8589 - val_mse: 20765804.0000\n",
            "Epoch 341/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1738.2372 - mae: 1738.2372 - mse: 20622340.0000 - val_loss: 1876.3710 - val_mae: 1876.3710 - val_mse: 20740442.0000\n",
            "Epoch 342/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1735.5353 - mae: 1735.5353 - mse: 20627324.0000 - val_loss: 1874.1416 - val_mae: 1874.1416 - val_mse: 20696922.0000\n",
            "Epoch 343/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1732.1676 - mae: 1732.1676 - mse: 20599000.0000 - val_loss: 1868.1235 - val_mae: 1868.1235 - val_mse: 20656606.0000\n",
            "Epoch 344/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1730.2056 - mae: 1730.2056 - mse: 20589862.0000 - val_loss: 1866.2609 - val_mae: 1866.2609 - val_mse: 20664820.0000\n",
            "Epoch 345/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1729.1346 - mae: 1729.1346 - mse: 20606270.0000 - val_loss: 1864.2561 - val_mae: 1864.2561 - val_mse: 20625138.0000\n",
            "Epoch 346/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1724.8729 - mae: 1724.8729 - mse: 20585534.0000 - val_loss: 1860.2245 - val_mae: 1860.2245 - val_mse: 20542904.0000\n",
            "Epoch 347/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1722.7167 - mae: 1722.7167 - mse: 20542040.0000 - val_loss: 1856.5903 - val_mae: 1856.5903 - val_mse: 20558834.0000\n",
            "Epoch 348/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1720.4283 - mae: 1720.4283 - mse: 20545082.0000 - val_loss: 1851.8973 - val_mae: 1851.8972 - val_mse: 20561846.0000\n",
            "Epoch 349/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1717.1272 - mae: 1717.1272 - mse: 20549746.0000 - val_loss: 1851.4390 - val_mae: 1851.4390 - val_mse: 20564944.0000\n",
            "Epoch 350/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1715.3020 - mae: 1715.3020 - mse: 20534500.0000 - val_loss: 1846.4772 - val_mae: 1846.4772 - val_mse: 20508954.0000\n",
            "Epoch 351/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1712.4700 - mae: 1712.4700 - mse: 20528594.0000 - val_loss: 1844.5225 - val_mae: 1844.5225 - val_mse: 20563162.0000\n",
            "Epoch 352/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1710.4957 - mae: 1710.4957 - mse: 20507392.0000 - val_loss: 1837.6808 - val_mae: 1837.6808 - val_mse: 20476402.0000\n",
            "Epoch 353/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1707.9229 - mae: 1707.9229 - mse: 20503232.0000 - val_loss: 1837.2745 - val_mae: 1837.2745 - val_mse: 20497456.0000\n",
            "Epoch 354/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1704.2372 - mae: 1704.2372 - mse: 20495250.0000 - val_loss: 1830.8972 - val_mae: 1830.8972 - val_mse: 20427156.0000\n",
            "Epoch 355/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1703.1869 - mae: 1703.1869 - mse: 20438650.0000 - val_loss: 1826.4398 - val_mae: 1826.4398 - val_mse: 20363530.0000\n",
            "Epoch 356/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1699.5240 - mae: 1699.5240 - mse: 20465494.0000 - val_loss: 1825.6427 - val_mae: 1825.6427 - val_mse: 20298596.0000\n",
            "Epoch 357/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1697.6522 - mae: 1697.6522 - mse: 20431578.0000 - val_loss: 1821.1289 - val_mae: 1821.1289 - val_mse: 20353776.0000\n",
            "Epoch 358/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1695.9829 - mae: 1695.9829 - mse: 20447792.0000 - val_loss: 1819.4242 - val_mae: 1819.4242 - val_mse: 20393838.0000\n",
            "Epoch 359/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1694.1515 - mae: 1694.1515 - mse: 20441590.0000 - val_loss: 1823.1407 - val_mae: 1823.1407 - val_mse: 20256768.0000\n",
            "Epoch 360/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1694.5269 - mae: 1694.5269 - mse: 20418268.0000 - val_loss: 1809.6450 - val_mae: 1809.6450 - val_mse: 20310458.0000\n",
            "Epoch 361/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1690.1865 - mae: 1690.1865 - mse: 20439478.0000 - val_loss: 1808.8016 - val_mae: 1808.8016 - val_mse: 20302750.0000\n",
            "Epoch 362/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1685.3738 - mae: 1685.3738 - mse: 20391292.0000 - val_loss: 1805.0109 - val_mae: 1805.0109 - val_mse: 20289436.0000\n",
            "Epoch 363/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1684.5851 - mae: 1684.5851 - mse: 20425228.0000 - val_loss: 1801.9467 - val_mae: 1801.9467 - val_mse: 20306276.0000\n",
            "Epoch 364/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1682.5742 - mae: 1682.5742 - mse: 20385536.0000 - val_loss: 1796.2194 - val_mae: 1796.2194 - val_mse: 20273652.0000\n",
            "Epoch 365/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1680.2010 - mae: 1680.2010 - mse: 20380684.0000 - val_loss: 1796.6130 - val_mae: 1796.6130 - val_mse: 20302628.0000\n",
            "Epoch 366/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1678.2911 - mae: 1678.2911 - mse: 20370858.0000 - val_loss: 1791.9448 - val_mae: 1791.9448 - val_mse: 20174006.0000\n",
            "Epoch 367/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1674.2955 - mae: 1674.2955 - mse: 20341020.0000 - val_loss: 1789.2550 - val_mae: 1789.2550 - val_mse: 20210300.0000\n",
            "Epoch 368/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1672.0037 - mae: 1672.0037 - mse: 20354404.0000 - val_loss: 1784.8153 - val_mae: 1784.8153 - val_mse: 20171492.0000\n",
            "Epoch 369/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1669.8364 - mae: 1669.8364 - mse: 20312186.0000 - val_loss: 1783.5070 - val_mae: 1783.5070 - val_mse: 20162172.0000\n",
            "Epoch 370/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1669.2284 - mae: 1669.2284 - mse: 20321886.0000 - val_loss: 1778.5582 - val_mae: 1778.5582 - val_mse: 20111770.0000\n",
            "Epoch 371/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1667.6199 - mae: 1667.6199 - mse: 20300034.0000 - val_loss: 1777.4048 - val_mae: 1777.4048 - val_mse: 20116502.0000\n",
            "Epoch 372/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1665.4722 - mae: 1665.4722 - mse: 20291978.0000 - val_loss: 1771.5713 - val_mae: 1771.5713 - val_mse: 20079514.0000\n",
            "Epoch 373/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1662.3690 - mae: 1662.3690 - mse: 20285246.0000 - val_loss: 1769.9353 - val_mae: 1769.9353 - val_mse: 20083178.0000\n",
            "Epoch 374/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1661.5968 - mae: 1661.5968 - mse: 20274224.0000 - val_loss: 1765.4459 - val_mae: 1765.4459 - val_mse: 20111120.0000\n",
            "Epoch 375/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1659.5341 - mae: 1659.5341 - mse: 20293664.0000 - val_loss: 1764.1260 - val_mae: 1764.1260 - val_mse: 20097166.0000\n",
            "Epoch 376/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1657.5490 - mae: 1657.5490 - mse: 20259782.0000 - val_loss: 1762.9136 - val_mae: 1762.9136 - val_mse: 20000728.0000\n",
            "Epoch 377/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1657.6260 - mae: 1657.6260 - mse: 20262380.0000 - val_loss: 1760.5020 - val_mae: 1760.5020 - val_mse: 19996644.0000\n",
            "Epoch 378/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1652.3014 - mae: 1652.3014 - mse: 20259490.0000 - val_loss: 1754.9225 - val_mae: 1754.9225 - val_mse: 19971156.0000\n",
            "Epoch 379/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1648.9838 - mae: 1648.9838 - mse: 20236580.0000 - val_loss: 1751.5184 - val_mae: 1751.5184 - val_mse: 19969544.0000\n",
            "Epoch 380/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1650.1915 - mae: 1650.1915 - mse: 20259022.0000 - val_loss: 1750.7358 - val_mae: 1750.7358 - val_mse: 19960068.0000\n",
            "Epoch 381/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1647.2246 - mae: 1647.2246 - mse: 20212894.0000 - val_loss: 1745.3784 - val_mae: 1745.3784 - val_mse: 19926788.0000\n",
            "Epoch 382/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1645.9076 - mae: 1645.9076 - mse: 20201150.0000 - val_loss: 1744.0509 - val_mae: 1744.0509 - val_mse: 19911414.0000\n",
            "Epoch 383/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1643.0304 - mae: 1643.0304 - mse: 20206518.0000 - val_loss: 1740.3755 - val_mae: 1740.3755 - val_mse: 19900456.0000\n",
            "Epoch 384/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1641.9965 - mae: 1641.9965 - mse: 20204780.0000 - val_loss: 1739.3949 - val_mae: 1739.3949 - val_mse: 19885890.0000\n",
            "Epoch 385/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1639.7900 - mae: 1639.7900 - mse: 20188238.0000 - val_loss: 1736.1534 - val_mae: 1736.1534 - val_mse: 19948584.0000\n",
            "Epoch 386/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1638.6628 - mae: 1638.6628 - mse: 20194026.0000 - val_loss: 1732.6732 - val_mae: 1732.6732 - val_mse: 19908414.0000\n",
            "Epoch 387/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1635.6251 - mae: 1635.6251 - mse: 20162734.0000 - val_loss: 1730.0269 - val_mae: 1730.0269 - val_mse: 19871776.0000\n",
            "Epoch 388/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1634.0200 - mae: 1634.0200 - mse: 20159950.0000 - val_loss: 1725.3785 - val_mae: 1725.3785 - val_mse: 19921992.0000\n",
            "Epoch 389/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1634.1134 - mae: 1634.1134 - mse: 20173960.0000 - val_loss: 1724.0088 - val_mae: 1724.0088 - val_mse: 19867284.0000\n",
            "Epoch 390/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1632.3303 - mae: 1632.3303 - mse: 20156188.0000 - val_loss: 1723.3423 - val_mae: 1723.3423 - val_mse: 19839288.0000\n",
            "Epoch 391/600\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1632.7598 - mae: 1632.7598 - mse: 20157100.0000 - val_loss: 1721.1451 - val_mae: 1721.1451 - val_mse: 19837188.0000\n",
            "Epoch 392/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1628.8573 - mae: 1628.8573 - mse: 20139968.0000 - val_loss: 1715.4530 - val_mae: 1715.4530 - val_mse: 19820140.0000\n",
            "Epoch 393/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1627.0308 - mae: 1627.0308 - mse: 20127102.0000 - val_loss: 1713.8184 - val_mae: 1713.8184 - val_mse: 19820868.0000\n",
            "Epoch 394/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1628.3990 - mae: 1628.3990 - mse: 20129008.0000 - val_loss: 1713.2010 - val_mae: 1713.2010 - val_mse: 19884388.0000\n",
            "Epoch 395/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1624.7695 - mae: 1624.7695 - mse: 20115366.0000 - val_loss: 1710.5438 - val_mae: 1710.5438 - val_mse: 19752706.0000\n",
            "Epoch 396/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1622.2640 - mae: 1622.2640 - mse: 20106164.0000 - val_loss: 1705.6553 - val_mae: 1705.6553 - val_mse: 19780666.0000\n",
            "Epoch 397/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1621.6132 - mae: 1621.6132 - mse: 20116140.0000 - val_loss: 1703.8730 - val_mae: 1703.8730 - val_mse: 19774258.0000\n",
            "Epoch 398/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1620.0931 - mae: 1620.0931 - mse: 20090284.0000 - val_loss: 1701.3770 - val_mae: 1701.3770 - val_mse: 19765576.0000\n",
            "Epoch 399/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1617.6650 - mae: 1617.6650 - mse: 20090672.0000 - val_loss: 1702.0897 - val_mae: 1702.0897 - val_mse: 19719846.0000\n",
            "Epoch 400/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1615.5237 - mae: 1615.5237 - mse: 20083076.0000 - val_loss: 1698.7683 - val_mae: 1698.7683 - val_mse: 19700882.0000\n",
            "Epoch 401/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1614.7853 - mae: 1614.7853 - mse: 20073214.0000 - val_loss: 1706.2130 - val_mae: 1706.2130 - val_mse: 19644124.0000\n",
            "Epoch 402/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1616.4983 - mae: 1616.4983 - mse: 20056782.0000 - val_loss: 1692.4187 - val_mae: 1692.4187 - val_mse: 19756216.0000\n",
            "Epoch 403/600\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1615.1136 - mae: 1615.1136 - mse: 20085048.0000 - val_loss: 1691.1870 - val_mae: 1691.1870 - val_mse: 19738016.0000\n",
            "Epoch 404/600\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1612.3042 - mae: 1612.3042 - mse: 20065614.0000 - val_loss: 1690.5035 - val_mae: 1690.5035 - val_mse: 19687604.0000\n",
            "Epoch 405/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1609.8896 - mae: 1609.8896 - mse: 20054694.0000 - val_loss: 1685.0099 - val_mae: 1685.0099 - val_mse: 19696606.0000\n",
            "Epoch 406/600\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1607.5417 - mae: 1607.5417 - mse: 20033336.0000 - val_loss: 1685.8584 - val_mae: 1685.8584 - val_mse: 19639190.0000\n",
            "Epoch 407/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1606.2388 - mae: 1606.2388 - mse: 20037628.0000 - val_loss: 1681.9928 - val_mae: 1681.9928 - val_mse: 19684414.0000\n",
            "Epoch 408/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1606.6610 - mae: 1606.6610 - mse: 20050866.0000 - val_loss: 1682.5698 - val_mae: 1682.5698 - val_mse: 19649106.0000\n",
            "Epoch 409/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1603.7397 - mae: 1603.7397 - mse: 20027390.0000 - val_loss: 1677.0015 - val_mae: 1677.0015 - val_mse: 19676300.0000\n",
            "Epoch 410/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1604.5375 - mae: 1604.5375 - mse: 20026492.0000 - val_loss: 1675.9543 - val_mae: 1675.9543 - val_mse: 19634260.0000\n",
            "Epoch 411/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1601.7629 - mae: 1601.7629 - mse: 20014578.0000 - val_loss: 1673.8613 - val_mae: 1673.8613 - val_mse: 19669796.0000\n",
            "Epoch 412/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1599.1259 - mae: 1599.1259 - mse: 20024290.0000 - val_loss: 1673.7058 - val_mae: 1673.7058 - val_mse: 19714132.0000\n",
            "Epoch 413/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1603.0745 - mae: 1603.0745 - mse: 20026484.0000 - val_loss: 1669.9338 - val_mae: 1669.9338 - val_mse: 19606150.0000\n",
            "Epoch 414/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1599.8358 - mae: 1599.8358 - mse: 19967284.0000 - val_loss: 1668.3834 - val_mae: 1668.3834 - val_mse: 19627366.0000\n",
            "Epoch 415/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1596.4331 - mae: 1596.4331 - mse: 19990728.0000 - val_loss: 1666.1451 - val_mae: 1666.1451 - val_mse: 19603132.0000\n",
            "Epoch 416/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1595.0038 - mae: 1595.0038 - mse: 19973664.0000 - val_loss: 1662.6665 - val_mae: 1662.6665 - val_mse: 19654024.0000\n",
            "Epoch 417/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1594.8091 - mae: 1594.8091 - mse: 19978514.0000 - val_loss: 1666.3348 - val_mae: 1666.3348 - val_mse: 19583464.0000\n",
            "Epoch 418/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1592.7584 - mae: 1592.7584 - mse: 19951992.0000 - val_loss: 1661.0577 - val_mae: 1661.0577 - val_mse: 19546664.0000\n",
            "Epoch 419/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1591.5283 - mae: 1591.5283 - mse: 19977084.0000 - val_loss: 1659.3350 - val_mae: 1659.3350 - val_mse: 19670172.0000\n",
            "Epoch 420/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1589.7963 - mae: 1589.7963 - mse: 19948196.0000 - val_loss: 1656.3137 - val_mae: 1656.3137 - val_mse: 19530410.0000\n",
            "Epoch 421/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1586.9445 - mae: 1586.9445 - mse: 19951694.0000 - val_loss: 1655.9554 - val_mae: 1655.9554 - val_mse: 19553842.0000\n",
            "Epoch 422/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1588.6993 - mae: 1588.6993 - mse: 19940250.0000 - val_loss: 1651.7252 - val_mae: 1651.7252 - val_mse: 19616436.0000\n",
            "Epoch 423/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1583.9110 - mae: 1583.9110 - mse: 19944168.0000 - val_loss: 1649.9221 - val_mae: 1649.9221 - val_mse: 19585352.0000\n",
            "Epoch 424/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1587.6910 - mae: 1587.6910 - mse: 19962814.0000 - val_loss: 1647.8905 - val_mae: 1647.8905 - val_mse: 19482598.0000\n",
            "Epoch 425/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1582.4121 - mae: 1582.4121 - mse: 19918810.0000 - val_loss: 1646.1315 - val_mae: 1646.1315 - val_mse: 19563924.0000\n",
            "Epoch 426/600\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1581.1436 - mae: 1581.1436 - mse: 19933106.0000 - val_loss: 1644.6935 - val_mae: 1644.6935 - val_mse: 19508166.0000\n",
            "Epoch 427/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1579.5513 - mae: 1579.5513 - mse: 19906342.0000 - val_loss: 1642.0571 - val_mae: 1642.0571 - val_mse: 19515592.0000\n",
            "Epoch 428/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1579.2358 - mae: 1579.2358 - mse: 19923198.0000 - val_loss: 1640.0647 - val_mae: 1640.0647 - val_mse: 19528002.0000\n",
            "Epoch 429/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1578.3231 - mae: 1578.3231 - mse: 19896092.0000 - val_loss: 1639.1707 - val_mae: 1639.1707 - val_mse: 19465816.0000\n",
            "Epoch 430/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1576.6874 - mae: 1576.6874 - mse: 19903028.0000 - val_loss: 1645.0535 - val_mae: 1645.0535 - val_mse: 19422260.0000\n",
            "Epoch 431/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1574.2867 - mae: 1574.2867 - mse: 19896578.0000 - val_loss: 1637.1473 - val_mae: 1637.1473 - val_mse: 19465172.0000\n",
            "Epoch 432/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1573.2086 - mae: 1573.2086 - mse: 19893422.0000 - val_loss: 1634.6421 - val_mae: 1634.6421 - val_mse: 19480668.0000\n",
            "Epoch 433/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1573.5448 - mae: 1573.5448 - mse: 19875154.0000 - val_loss: 1631.8342 - val_mae: 1631.8342 - val_mse: 19459930.0000\n",
            "Epoch 434/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1572.3206 - mae: 1572.3206 - mse: 19897572.0000 - val_loss: 1629.8556 - val_mae: 1629.8556 - val_mse: 19438340.0000\n",
            "Epoch 435/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1571.3202 - mae: 1571.3202 - mse: 19897882.0000 - val_loss: 1630.4211 - val_mae: 1630.4211 - val_mse: 19431460.0000\n",
            "Epoch 436/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1569.5764 - mae: 1569.5764 - mse: 19870622.0000 - val_loss: 1626.1278 - val_mae: 1626.1278 - val_mse: 19467286.0000\n",
            "Epoch 437/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1568.9510 - mae: 1568.9510 - mse: 19874788.0000 - val_loss: 1627.3824 - val_mae: 1627.3824 - val_mse: 19401340.0000\n",
            "Epoch 438/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1567.4531 - mae: 1567.4531 - mse: 19867342.0000 - val_loss: 1625.0662 - val_mae: 1625.0662 - val_mse: 19434894.0000\n",
            "Epoch 439/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1565.3553 - mae: 1565.3553 - mse: 19855570.0000 - val_loss: 1621.7290 - val_mae: 1621.7290 - val_mse: 19461896.0000\n",
            "Epoch 440/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1564.7684 - mae: 1564.7684 - mse: 19847806.0000 - val_loss: 1623.9504 - val_mae: 1623.9504 - val_mse: 19399074.0000\n",
            "Epoch 441/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1563.1226 - mae: 1563.1226 - mse: 19840340.0000 - val_loss: 1617.3052 - val_mae: 1617.3052 - val_mse: 19435802.0000\n",
            "Epoch 442/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1562.6891 - mae: 1562.6891 - mse: 19859808.0000 - val_loss: 1619.6704 - val_mae: 1619.6704 - val_mse: 19396920.0000\n",
            "Epoch 443/600\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1559.8751 - mae: 1559.8751 - mse: 19832276.0000 - val_loss: 1617.4187 - val_mae: 1617.4187 - val_mse: 19429090.0000\n",
            "Epoch 444/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1562.9814 - mae: 1562.9814 - mse: 19836802.0000 - val_loss: 1613.2754 - val_mae: 1613.2754 - val_mse: 19389516.0000\n",
            "Epoch 445/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1559.4210 - mae: 1559.4210 - mse: 19831494.0000 - val_loss: 1612.6592 - val_mae: 1612.6592 - val_mse: 19385078.0000\n",
            "Epoch 446/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1557.2208 - mae: 1557.2208 - mse: 19828976.0000 - val_loss: 1610.6809 - val_mae: 1610.6809 - val_mse: 19384194.0000\n",
            "Epoch 447/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1555.9850 - mae: 1555.9850 - mse: 19828276.0000 - val_loss: 1609.2639 - val_mae: 1609.2639 - val_mse: 19447116.0000\n",
            "Epoch 448/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1555.1996 - mae: 1555.1996 - mse: 19823596.0000 - val_loss: 1607.0497 - val_mae: 1607.0497 - val_mse: 19355592.0000\n",
            "Epoch 449/600\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1553.5656 - mae: 1553.5656 - mse: 19806984.0000 - val_loss: 1604.4398 - val_mae: 1604.4398 - val_mse: 19345466.0000\n",
            "Epoch 450/600\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1552.4539 - mae: 1552.4539 - mse: 19817794.0000 - val_loss: 1603.5111 - val_mae: 1603.5111 - val_mse: 19399496.0000\n",
            "Epoch 451/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1550.9778 - mae: 1550.9778 - mse: 19792532.0000 - val_loss: 1600.4854 - val_mae: 1600.4854 - val_mse: 19340104.0000\n",
            "Epoch 452/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1551.5767 - mae: 1551.5767 - mse: 19781210.0000 - val_loss: 1604.8639 - val_mae: 1604.8639 - val_mse: 19313784.0000\n",
            "Epoch 453/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1550.4980 - mae: 1550.4980 - mse: 19806264.0000 - val_loss: 1600.5206 - val_mae: 1600.5206 - val_mse: 19318500.0000\n",
            "Epoch 454/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1548.8373 - mae: 1548.8373 - mse: 19795216.0000 - val_loss: 1595.5037 - val_mae: 1595.5037 - val_mse: 19385024.0000\n",
            "Epoch 455/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1547.3997 - mae: 1547.3997 - mse: 19787100.0000 - val_loss: 1596.5106 - val_mae: 1596.5106 - val_mse: 19277182.0000\n",
            "Epoch 456/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1546.6334 - mae: 1546.6334 - mse: 19791688.0000 - val_loss: 1592.9098 - val_mae: 1592.9098 - val_mse: 19341876.0000\n",
            "Epoch 457/600\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1546.1860 - mae: 1546.1860 - mse: 19776076.0000 - val_loss: 1591.3198 - val_mae: 1591.3198 - val_mse: 19304596.0000\n",
            "Epoch 458/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1543.8997 - mae: 1543.8997 - mse: 19779600.0000 - val_loss: 1589.5015 - val_mae: 1589.5015 - val_mse: 19267276.0000\n",
            "Epoch 459/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1542.7904 - mae: 1542.7904 - mse: 19762902.0000 - val_loss: 1587.0245 - val_mae: 1587.0245 - val_mse: 19298308.0000\n",
            "Epoch 460/600\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1540.7520 - mae: 1540.7520 - mse: 19772610.0000 - val_loss: 1587.0356 - val_mae: 1587.0356 - val_mse: 19363570.0000\n",
            "Epoch 461/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1541.7361 - mae: 1541.7361 - mse: 19768566.0000 - val_loss: 1586.6738 - val_mae: 1586.6738 - val_mse: 19253078.0000\n",
            "Epoch 462/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1540.9579 - mae: 1540.9579 - mse: 19764502.0000 - val_loss: 1586.3922 - val_mae: 1586.3922 - val_mse: 19275142.0000\n",
            "Epoch 463/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1538.8829 - mae: 1538.8829 - mse: 19762630.0000 - val_loss: 1582.0753 - val_mae: 1582.0753 - val_mse: 19284490.0000\n",
            "Epoch 464/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1538.7252 - mae: 1538.7252 - mse: 19754876.0000 - val_loss: 1579.7628 - val_mae: 1579.7628 - val_mse: 19273134.0000\n",
            "Epoch 465/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1537.5853 - mae: 1537.5853 - mse: 19749536.0000 - val_loss: 1577.3563 - val_mae: 1577.3563 - val_mse: 19284198.0000\n",
            "Epoch 466/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1538.9491 - mae: 1538.9491 - mse: 19766304.0000 - val_loss: 1575.7328 - val_mae: 1575.7328 - val_mse: 19267644.0000\n",
            "Epoch 467/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1535.4747 - mae: 1535.4747 - mse: 19746374.0000 - val_loss: 1572.7560 - val_mae: 1572.7560 - val_mse: 19252740.0000\n",
            "Epoch 468/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1534.7250 - mae: 1534.7250 - mse: 19740488.0000 - val_loss: 1572.1692 - val_mae: 1572.1692 - val_mse: 19275992.0000\n",
            "Epoch 469/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1534.0953 - mae: 1534.0953 - mse: 19754902.0000 - val_loss: 1571.4419 - val_mae: 1571.4419 - val_mse: 19279034.0000\n",
            "Epoch 470/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1532.6825 - mae: 1532.6825 - mse: 19741000.0000 - val_loss: 1569.1810 - val_mae: 1569.1810 - val_mse: 19268496.0000\n",
            "Epoch 471/600\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1532.8549 - mae: 1532.8549 - mse: 19739736.0000 - val_loss: 1569.9648 - val_mae: 1569.9648 - val_mse: 19248346.0000\n",
            "Epoch 472/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1529.9657 - mae: 1529.9657 - mse: 19736148.0000 - val_loss: 1565.7135 - val_mae: 1565.7135 - val_mse: 19259384.0000\n",
            "Epoch 473/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1529.8542 - mae: 1529.8542 - mse: 19741818.0000 - val_loss: 1565.3444 - val_mae: 1565.3444 - val_mse: 19244822.0000\n",
            "Epoch 474/600\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1529.4218 - mae: 1529.4218 - mse: 19747626.0000 - val_loss: 1562.7692 - val_mae: 1562.7692 - val_mse: 19279612.0000\n",
            "Epoch 475/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1527.2250 - mae: 1527.2250 - mse: 19736950.0000 - val_loss: 1561.1627 - val_mae: 1561.1627 - val_mse: 19248688.0000\n",
            "Epoch 476/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1526.7242 - mae: 1526.7242 - mse: 19724088.0000 - val_loss: 1559.9407 - val_mae: 1559.9407 - val_mse: 19216474.0000\n",
            "Epoch 477/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1526.6589 - mae: 1526.6589 - mse: 19724464.0000 - val_loss: 1558.3920 - val_mae: 1558.3920 - val_mse: 19275582.0000\n",
            "Epoch 478/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1526.8704 - mae: 1526.8704 - mse: 19726310.0000 - val_loss: 1555.7944 - val_mae: 1555.7944 - val_mse: 19216056.0000\n",
            "Epoch 479/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1525.4635 - mae: 1525.4635 - mse: 19712364.0000 - val_loss: 1553.9420 - val_mae: 1553.9420 - val_mse: 19241716.0000\n",
            "Epoch 480/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1525.7990 - mae: 1525.7990 - mse: 19712050.0000 - val_loss: 1554.5000 - val_mae: 1554.5000 - val_mse: 19263368.0000\n",
            "Epoch 481/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1524.8108 - mae: 1524.8108 - mse: 19702396.0000 - val_loss: 1552.3309 - val_mae: 1552.3309 - val_mse: 19286810.0000\n",
            "Epoch 482/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1522.0514 - mae: 1522.0514 - mse: 19711820.0000 - val_loss: 1549.9464 - val_mae: 1549.9464 - val_mse: 19261344.0000\n",
            "Epoch 483/600\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1522.0615 - mae: 1522.0615 - mse: 19697258.0000 - val_loss: 1549.9966 - val_mae: 1549.9966 - val_mse: 19233550.0000\n",
            "Epoch 484/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1519.2664 - mae: 1519.2664 - mse: 19706080.0000 - val_loss: 1547.6138 - val_mae: 1547.6138 - val_mse: 19211566.0000\n",
            "Epoch 485/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1519.3499 - mae: 1519.3499 - mse: 19693944.0000 - val_loss: 1546.1304 - val_mae: 1546.1304 - val_mse: 19254704.0000\n",
            "Epoch 486/600\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1518.4863 - mae: 1518.4863 - mse: 19689102.0000 - val_loss: 1546.0404 - val_mae: 1546.0404 - val_mse: 19229162.0000\n",
            "Epoch 487/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1518.7791 - mae: 1518.7791 - mse: 19667296.0000 - val_loss: 1545.1720 - val_mae: 1545.1720 - val_mse: 19281978.0000\n",
            "Epoch 488/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1517.2538 - mae: 1517.2538 - mse: 19691998.0000 - val_loss: 1541.9500 - val_mae: 1541.9500 - val_mse: 19245134.0000\n",
            "Epoch 489/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1517.6379 - mae: 1517.6379 - mse: 19682382.0000 - val_loss: 1541.1405 - val_mae: 1541.1405 - val_mse: 19269554.0000\n",
            "Epoch 490/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1518.6915 - mae: 1518.6915 - mse: 19707154.0000 - val_loss: 1540.8513 - val_mae: 1540.8513 - val_mse: 19215794.0000\n",
            "Epoch 491/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1514.6758 - mae: 1514.6758 - mse: 19682436.0000 - val_loss: 1541.0485 - val_mae: 1541.0485 - val_mse: 19232552.0000\n",
            "Epoch 492/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1515.5402 - mae: 1515.5402 - mse: 19683122.0000 - val_loss: 1537.8805 - val_mae: 1537.8805 - val_mse: 19272974.0000\n",
            "Epoch 493/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1514.9437 - mae: 1514.9437 - mse: 19673706.0000 - val_loss: 1538.0341 - val_mae: 1538.0341 - val_mse: 19178100.0000\n",
            "Epoch 494/600\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1513.2745 - mae: 1513.2745 - mse: 19660242.0000 - val_loss: 1536.4512 - val_mae: 1536.4512 - val_mse: 19235120.0000\n",
            "Epoch 495/600\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1512.2737 - mae: 1512.2737 - mse: 19653810.0000 - val_loss: 1534.2976 - val_mae: 1534.2976 - val_mse: 19224116.0000\n",
            "Epoch 496/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1511.0950 - mae: 1511.0950 - mse: 19665020.0000 - val_loss: 1531.2123 - val_mae: 1531.2123 - val_mse: 19230830.0000\n",
            "Epoch 497/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1510.4514 - mae: 1510.4514 - mse: 19670056.0000 - val_loss: 1531.1599 - val_mae: 1531.1599 - val_mse: 19245582.0000\n",
            "Epoch 498/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1509.5701 - mae: 1509.5701 - mse: 19667156.0000 - val_loss: 1529.9983 - val_mae: 1529.9983 - val_mse: 19239192.0000\n",
            "Epoch 499/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1512.7153 - mae: 1512.7153 - mse: 19671664.0000 - val_loss: 1530.9121 - val_mae: 1530.9121 - val_mse: 19296024.0000\n",
            "Epoch 500/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1509.2743 - mae: 1509.2743 - mse: 19665936.0000 - val_loss: 1528.6486 - val_mae: 1528.6486 - val_mse: 19215336.0000\n",
            "Epoch 501/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1508.6479 - mae: 1508.6479 - mse: 19649576.0000 - val_loss: 1526.2477 - val_mae: 1526.2477 - val_mse: 19253946.0000\n",
            "Epoch 502/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1507.7848 - mae: 1507.7848 - mse: 19655476.0000 - val_loss: 1528.0002 - val_mae: 1528.0002 - val_mse: 19242962.0000\n",
            "Epoch 503/600\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1506.7825 - mae: 1506.7825 - mse: 19650178.0000 - val_loss: 1526.5657 - val_mae: 1526.5657 - val_mse: 19227598.0000\n",
            "Epoch 504/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1507.2811 - mae: 1507.2811 - mse: 19657232.0000 - val_loss: 1522.4700 - val_mae: 1522.4700 - val_mse: 19234850.0000\n",
            "Epoch 505/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1503.8242 - mae: 1503.8242 - mse: 19648656.0000 - val_loss: 1523.1028 - val_mae: 1523.1028 - val_mse: 19272568.0000\n",
            "Epoch 506/600\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1506.4437 - mae: 1506.4437 - mse: 19641780.0000 - val_loss: 1522.7715 - val_mae: 1522.7715 - val_mse: 19206566.0000\n",
            "Epoch 507/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1507.2642 - mae: 1507.2642 - mse: 19644806.0000 - val_loss: 1522.3115 - val_mae: 1522.3115 - val_mse: 19221838.0000\n",
            "Epoch 508/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1504.6460 - mae: 1504.6460 - mse: 19636584.0000 - val_loss: 1517.1488 - val_mae: 1517.1488 - val_mse: 19261624.0000\n",
            "Epoch 509/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1503.7081 - mae: 1503.7081 - mse: 19630362.0000 - val_loss: 1519.0079 - val_mae: 1519.0079 - val_mse: 19224494.0000\n",
            "Epoch 510/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1502.1846 - mae: 1502.1846 - mse: 19632270.0000 - val_loss: 1517.2448 - val_mae: 1517.2448 - val_mse: 19236128.0000\n",
            "Epoch 511/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1502.5454 - mae: 1502.5454 - mse: 19625220.0000 - val_loss: 1516.2887 - val_mae: 1516.2887 - val_mse: 19284106.0000\n",
            "Epoch 512/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1501.4583 - mae: 1501.4583 - mse: 19634324.0000 - val_loss: 1513.6422 - val_mae: 1513.6422 - val_mse: 19223652.0000\n",
            "Epoch 513/600\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1501.0729 - mae: 1501.0729 - mse: 19627236.0000 - val_loss: 1514.0452 - val_mae: 1514.0452 - val_mse: 19202306.0000\n",
            "Epoch 514/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1499.4839 - mae: 1499.4839 - mse: 19618948.0000 - val_loss: 1514.8689 - val_mae: 1514.8689 - val_mse: 19263676.0000\n",
            "Epoch 515/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1501.7583 - mae: 1501.7583 - mse: 19611724.0000 - val_loss: 1512.4991 - val_mae: 1512.4991 - val_mse: 19208040.0000\n",
            "Epoch 516/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1499.6428 - mae: 1499.6428 - mse: 19631846.0000 - val_loss: 1511.6934 - val_mae: 1511.6934 - val_mse: 19236002.0000\n",
            "Epoch 517/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1498.2076 - mae: 1498.2076 - mse: 19616528.0000 - val_loss: 1509.3358 - val_mae: 1509.3358 - val_mse: 19278596.0000\n",
            "Epoch 518/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1497.1205 - mae: 1497.1205 - mse: 19620758.0000 - val_loss: 1508.1624 - val_mae: 1508.1624 - val_mse: 19236062.0000\n",
            "Epoch 519/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1496.7396 - mae: 1496.7396 - mse: 19602620.0000 - val_loss: 1506.0660 - val_mae: 1506.0660 - val_mse: 19259412.0000\n",
            "Epoch 520/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1495.3447 - mae: 1495.3447 - mse: 19610508.0000 - val_loss: 1505.3711 - val_mae: 1505.3711 - val_mse: 19260378.0000\n",
            "Epoch 521/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1495.0006 - mae: 1495.0006 - mse: 19613154.0000 - val_loss: 1505.1206 - val_mae: 1505.1206 - val_mse: 19179324.0000\n",
            "Epoch 522/600\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1494.5250 - mae: 1494.5250 - mse: 19591956.0000 - val_loss: 1506.8029 - val_mae: 1506.8029 - val_mse: 19310138.0000\n",
            "Epoch 523/600\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1496.9884 - mae: 1496.9884 - mse: 19625840.0000 - val_loss: 1510.3826 - val_mae: 1510.3826 - val_mse: 19144948.0000\n",
            "Epoch 524/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1496.9886 - mae: 1496.9886 - mse: 19608514.0000 - val_loss: 1501.9801 - val_mae: 1501.9801 - val_mse: 19276832.0000\n",
            "Epoch 525/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1493.9574 - mae: 1493.9574 - mse: 19605094.0000 - val_loss: 1499.7476 - val_mae: 1499.7476 - val_mse: 19233714.0000\n",
            "Epoch 526/600\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1496.1805 - mae: 1496.1805 - mse: 19586428.0000 - val_loss: 1498.7435 - val_mae: 1498.7435 - val_mse: 19200202.0000\n",
            "Epoch 527/600\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1493.7012 - mae: 1493.7012 - mse: 19594132.0000 - val_loss: 1497.3557 - val_mae: 1497.3557 - val_mse: 19214118.0000\n",
            "Epoch 528/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1491.8745 - mae: 1491.8745 - mse: 19580826.0000 - val_loss: 1497.7375 - val_mae: 1497.7375 - val_mse: 19259934.0000\n",
            "Epoch 529/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1492.3728 - mae: 1492.3728 - mse: 19591860.0000 - val_loss: 1498.7551 - val_mae: 1498.7551 - val_mse: 19175610.0000\n",
            "Epoch 530/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1492.0034 - mae: 1492.0034 - mse: 19580246.0000 - val_loss: 1499.1669 - val_mae: 1499.1669 - val_mse: 19156756.0000\n",
            "Epoch 531/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1491.0468 - mae: 1491.0468 - mse: 19577660.0000 - val_loss: 1494.6602 - val_mae: 1494.6602 - val_mse: 19251950.0000\n",
            "Epoch 532/600\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1490.3636 - mae: 1490.3636 - mse: 19570366.0000 - val_loss: 1496.4180 - val_mae: 1496.4180 - val_mse: 19183204.0000\n",
            "Epoch 533/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1490.4418 - mae: 1490.4418 - mse: 19558488.0000 - val_loss: 1490.8668 - val_mae: 1490.8668 - val_mse: 19196364.0000\n",
            "Epoch 534/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1489.7313 - mae: 1489.7313 - mse: 19554638.0000 - val_loss: 1491.6360 - val_mae: 1491.6360 - val_mse: 19236388.0000\n",
            "Epoch 535/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1489.6497 - mae: 1489.6497 - mse: 19573366.0000 - val_loss: 1488.5526 - val_mae: 1488.5526 - val_mse: 19218282.0000\n",
            "Epoch 536/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1487.9028 - mae: 1487.9028 - mse: 19568488.0000 - val_loss: 1489.8016 - val_mae: 1489.8016 - val_mse: 19173636.0000\n",
            "Epoch 537/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1487.1027 - mae: 1487.1027 - mse: 19573868.0000 - val_loss: 1486.2960 - val_mae: 1486.2960 - val_mse: 19176666.0000\n",
            "Epoch 538/600\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1484.4888 - mae: 1484.4888 - mse: 19562548.0000 - val_loss: 1486.8275 - val_mae: 1486.8275 - val_mse: 19177002.0000\n",
            "Epoch 539/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1485.8077 - mae: 1485.8077 - mse: 19570458.0000 - val_loss: 1485.9150 - val_mae: 1485.9150 - val_mse: 19197424.0000\n",
            "Epoch 540/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1486.3400 - mae: 1486.3400 - mse: 19558134.0000 - val_loss: 1485.7383 - val_mae: 1485.7383 - val_mse: 19236252.0000\n",
            "Epoch 541/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1484.1071 - mae: 1484.1071 - mse: 19563942.0000 - val_loss: 1489.4246 - val_mae: 1489.4246 - val_mse: 19164516.0000\n",
            "Epoch 542/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1484.5559 - mae: 1484.5559 - mse: 19538624.0000 - val_loss: 1483.7041 - val_mae: 1483.7041 - val_mse: 19226110.0000\n",
            "Epoch 543/600\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1483.9608 - mae: 1483.9608 - mse: 19552736.0000 - val_loss: 1482.0752 - val_mae: 1482.0752 - val_mse: 19182158.0000\n",
            "Epoch 544/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1483.4143 - mae: 1483.4143 - mse: 19535604.0000 - val_loss: 1480.1997 - val_mae: 1480.1997 - val_mse: 19231030.0000\n",
            "Epoch 545/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1483.7212 - mae: 1483.7212 - mse: 19548452.0000 - val_loss: 1484.5226 - val_mae: 1484.5226 - val_mse: 19166792.0000\n",
            "Epoch 546/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1481.5883 - mae: 1481.5883 - mse: 19526690.0000 - val_loss: 1479.0260 - val_mae: 1479.0260 - val_mse: 19237786.0000\n",
            "Epoch 547/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1481.2510 - mae: 1481.2510 - mse: 19546324.0000 - val_loss: 1479.8361 - val_mae: 1479.8361 - val_mse: 19203318.0000\n",
            "Epoch 548/600\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1479.5339 - mae: 1479.5339 - mse: 19540830.0000 - val_loss: 1483.2094 - val_mae: 1483.2094 - val_mse: 19135642.0000\n",
            "Epoch 549/600\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1482.2120 - mae: 1482.2120 - mse: 19527994.0000 - val_loss: 1475.9316 - val_mae: 1475.9316 - val_mse: 19195500.0000\n",
            "Epoch 550/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1479.7535 - mae: 1479.7535 - mse: 19532096.0000 - val_loss: 1476.4916 - val_mae: 1476.4916 - val_mse: 19268524.0000\n",
            "Epoch 551/600\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1481.3284 - mae: 1481.3284 - mse: 19533924.0000 - val_loss: 1476.6755 - val_mae: 1476.6755 - val_mse: 19168722.0000\n",
            "Epoch 552/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1477.8126 - mae: 1477.8126 - mse: 19541158.0000 - val_loss: 1472.7344 - val_mae: 1472.7344 - val_mse: 19192654.0000\n",
            "Epoch 553/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1477.5007 - mae: 1477.5007 - mse: 19532414.0000 - val_loss: 1472.9082 - val_mae: 1472.9082 - val_mse: 19187828.0000\n",
            "Epoch 554/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1477.2402 - mae: 1477.2402 - mse: 19520788.0000 - val_loss: 1471.9626 - val_mae: 1471.9626 - val_mse: 19193422.0000\n",
            "Epoch 555/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1475.7321 - mae: 1475.7321 - mse: 19523160.0000 - val_loss: 1470.8784 - val_mae: 1470.8784 - val_mse: 19184894.0000\n",
            "Epoch 556/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1475.6515 - mae: 1475.6515 - mse: 19510208.0000 - val_loss: 1471.8890 - val_mae: 1471.8890 - val_mse: 19241830.0000\n",
            "Epoch 557/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1476.8386 - mae: 1476.8386 - mse: 19515384.0000 - val_loss: 1469.5095 - val_mae: 1469.5095 - val_mse: 19168156.0000\n",
            "Epoch 558/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1474.4563 - mae: 1474.4563 - mse: 19514674.0000 - val_loss: 1470.4755 - val_mae: 1470.4755 - val_mse: 19233264.0000\n",
            "Epoch 559/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1474.2159 - mae: 1474.2159 - mse: 19510610.0000 - val_loss: 1467.7686 - val_mae: 1467.7686 - val_mse: 19198176.0000\n",
            "Epoch 560/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1473.5074 - mae: 1473.5074 - mse: 19509520.0000 - val_loss: 1472.0972 - val_mae: 1472.0972 - val_mse: 19126124.0000\n",
            "Epoch 561/600\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1474.0203 - mae: 1474.0203 - mse: 19490092.0000 - val_loss: 1465.8662 - val_mae: 1465.8662 - val_mse: 19227114.0000\n",
            "Epoch 562/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1473.7804 - mae: 1473.7804 - mse: 19505588.0000 - val_loss: 1473.3606 - val_mae: 1473.3606 - val_mse: 19129928.0000\n",
            "Epoch 563/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1474.5612 - mae: 1474.5612 - mse: 19498460.0000 - val_loss: 1463.9285 - val_mae: 1463.9285 - val_mse: 19191080.0000\n",
            "Epoch 564/600\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1470.4078 - mae: 1470.4078 - mse: 19491240.0000 - val_loss: 1464.6515 - val_mae: 1464.6515 - val_mse: 19175184.0000\n",
            "Epoch 565/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1470.8669 - mae: 1470.8669 - mse: 19497172.0000 - val_loss: 1463.4554 - val_mae: 1463.4554 - val_mse: 19153470.0000\n",
            "Epoch 566/600\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1471.9531 - mae: 1471.9531 - mse: 19486492.0000 - val_loss: 1462.0380 - val_mae: 1462.0380 - val_mse: 19165862.0000\n",
            "Epoch 567/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1469.5266 - mae: 1469.5266 - mse: 19485474.0000 - val_loss: 1463.9078 - val_mae: 1463.9078 - val_mse: 19180162.0000\n",
            "Epoch 568/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1469.4783 - mae: 1469.4783 - mse: 19491448.0000 - val_loss: 1460.8812 - val_mae: 1460.8812 - val_mse: 19184700.0000\n",
            "Epoch 569/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1467.8016 - mae: 1467.8016 - mse: 19487560.0000 - val_loss: 1459.4303 - val_mae: 1459.4303 - val_mse: 19172022.0000\n",
            "Epoch 570/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1466.7871 - mae: 1466.7871 - mse: 19483480.0000 - val_loss: 1460.0751 - val_mae: 1460.0751 - val_mse: 19181558.0000\n",
            "Epoch 571/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1467.4199 - mae: 1467.4199 - mse: 19473460.0000 - val_loss: 1461.3042 - val_mae: 1461.3042 - val_mse: 19160786.0000\n",
            "Epoch 572/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1467.6312 - mae: 1467.6312 - mse: 19477190.0000 - val_loss: 1458.8760 - val_mae: 1458.8760 - val_mse: 19173380.0000\n",
            "Epoch 573/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1469.3383 - mae: 1469.3383 - mse: 19497738.0000 - val_loss: 1462.0370 - val_mae: 1462.0370 - val_mse: 19106460.0000\n",
            "Epoch 574/600\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1469.4586 - mae: 1469.4586 - mse: 19448002.0000 - val_loss: 1456.9552 - val_mae: 1456.9552 - val_mse: 19188280.0000\n",
            "Epoch 575/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1464.7544 - mae: 1464.7544 - mse: 19471860.0000 - val_loss: 1454.6139 - val_mae: 1454.6139 - val_mse: 19156310.0000\n",
            "Epoch 576/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1464.4585 - mae: 1464.4585 - mse: 19483408.0000 - val_loss: 1457.2430 - val_mae: 1457.2430 - val_mse: 19116566.0000\n",
            "Epoch 577/600\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1466.8658 - mae: 1466.8658 - mse: 19461586.0000 - val_loss: 1453.7661 - val_mae: 1453.7661 - val_mse: 19173866.0000\n",
            "Epoch 578/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1467.7240 - mae: 1467.7240 - mse: 19456106.0000 - val_loss: 1451.2015 - val_mae: 1451.2015 - val_mse: 19132674.0000\n",
            "Epoch 579/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1464.5002 - mae: 1464.5002 - mse: 19441380.0000 - val_loss: 1454.6895 - val_mae: 1454.6895 - val_mse: 19182916.0000\n",
            "Epoch 580/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1463.1854 - mae: 1463.1854 - mse: 19462820.0000 - val_loss: 1452.2225 - val_mae: 1452.2225 - val_mse: 19124500.0000\n",
            "Epoch 581/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1462.7086 - mae: 1462.7086 - mse: 19464384.0000 - val_loss: 1459.1302 - val_mae: 1459.1302 - val_mse: 19059996.0000\n",
            "Epoch 582/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1465.5248 - mae: 1465.5248 - mse: 19446518.0000 - val_loss: 1449.7456 - val_mae: 1449.7456 - val_mse: 19091490.0000\n",
            "Epoch 583/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1461.5010 - mae: 1461.5010 - mse: 19429914.0000 - val_loss: 1448.7085 - val_mae: 1448.7085 - val_mse: 19137040.0000\n",
            "Epoch 584/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1461.8871 - mae: 1461.8871 - mse: 19445330.0000 - val_loss: 1449.7465 - val_mae: 1449.7465 - val_mse: 19132466.0000\n",
            "Epoch 585/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1459.0966 - mae: 1459.0966 - mse: 19439808.0000 - val_loss: 1448.7059 - val_mae: 1448.7059 - val_mse: 19188322.0000\n",
            "Epoch 586/600\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1461.2252 - mae: 1461.2252 - mse: 19455492.0000 - val_loss: 1451.8602 - val_mae: 1451.8602 - val_mse: 19095128.0000\n",
            "Epoch 587/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1464.3160 - mae: 1464.3160 - mse: 19435174.0000 - val_loss: 1451.4041 - val_mae: 1451.4041 - val_mse: 19195436.0000\n",
            "Epoch 588/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1460.3656 - mae: 1460.3656 - mse: 19431752.0000 - val_loss: 1445.5876 - val_mae: 1445.5876 - val_mse: 19110068.0000\n",
            "Epoch 589/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1458.0118 - mae: 1458.0118 - mse: 19425102.0000 - val_loss: 1445.1669 - val_mae: 1445.1669 - val_mse: 19148820.0000\n",
            "Epoch 590/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1459.0128 - mae: 1459.0128 - mse: 19440974.0000 - val_loss: 1448.5887 - val_mae: 1448.5887 - val_mse: 19067668.0000\n",
            "Epoch 591/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1460.0603 - mae: 1460.0603 - mse: 19406262.0000 - val_loss: 1444.7185 - val_mae: 1444.7185 - val_mse: 19154374.0000\n",
            "Epoch 592/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1457.0508 - mae: 1457.0508 - mse: 19423790.0000 - val_loss: 1442.3455 - val_mae: 1442.3455 - val_mse: 19127746.0000\n",
            "Epoch 593/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1456.4559 - mae: 1456.4559 - mse: 19423222.0000 - val_loss: 1443.5847 - val_mae: 1443.5847 - val_mse: 19123612.0000\n",
            "Epoch 594/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1455.9829 - mae: 1455.9829 - mse: 19432166.0000 - val_loss: 1441.8654 - val_mae: 1441.8654 - val_mse: 19156824.0000\n",
            "Epoch 595/600\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1455.0463 - mae: 1455.0463 - mse: 19401300.0000 - val_loss: 1439.4489 - val_mae: 1439.4489 - val_mse: 19147676.0000\n",
            "Epoch 596/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1454.4701 - mae: 1454.4701 - mse: 19417124.0000 - val_loss: 1441.6671 - val_mae: 1441.6671 - val_mse: 19109346.0000\n",
            "Epoch 597/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1453.0057 - mae: 1453.0057 - mse: 19404810.0000 - val_loss: 1441.2354 - val_mae: 1441.2354 - val_mse: 19117938.0000\n",
            "Epoch 598/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1452.4493 - mae: 1452.4493 - mse: 19413362.0000 - val_loss: 1439.1155 - val_mae: 1439.1155 - val_mse: 19125380.0000\n",
            "Epoch 599/600\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1454.5841 - mae: 1454.5841 - mse: 19411870.0000 - val_loss: 1439.5581 - val_mae: 1439.5581 - val_mse: 19116096.0000\n",
            "Epoch 600/600\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1450.9050 - mae: 1450.9050 - mse: 19395466.0000 - val_loss: 1435.4430 - val_mae: 1435.4430 - val_mse: 19098952.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This cell defines a plotting function for the loss parameter of the model during training, throughout its different epochs -> this is for its validation and training datasets (on the same graph)\n",
        "#The argument this takes is a trained model (in the syntax of the outputted trained model from the previous cell)\n",
        "\n",
        "\"\"\"\n",
        "\tContext:\n",
        "\t\t-> The previous cell trained the model with 600 epochs and stored the values from this in the variable called `history`\n",
        "\t\t-> When we initialised the architecture for the neural network this uses, we asked it to return two parameters which were the MAE and MSE <- the Mean Absolute Error and the Mean Squared Error (information about the accuracy of its training)\n",
        "\t\t-> This information from training the model is stored in the `history` variable -> for all of the different epochs which we've had it perform\n",
        "\n",
        "\tDefining a function to plot this:\n",
        "\t\t-> The argument to this function is the variable from the previous cell (the data we get from training the model)\n",
        "\t\t-> This function takes this data and plots two of the values on the same figure it returns\n",
        "\t\t\t-> These two values are the loss function after each epoch, obtained while performing gradient descent\n",
        "\t\t\t-> The values of this function correspond to the accuracy of the model while training the model on 80% of its data\n",
        "\t\t\t-> The other variable this plots is val_loss\n",
        "\t\t\t-> 80% of the entire dataset is training data -> 20% of that 80% is validation data\n",
        "\t\t\t-> We are performing gradient descent on both the training and validation data\n",
        "\t\t\t-> We are doing it on both of them at the same time to see how different they are -> we know that if the model produces wildly different predictions for the validation data then it may have overfit for the training data (in other words the number of epochs we are using may be too high)\n",
        "\t\t\t-> The second value we are plotting is the loss function we are using to train the model with - on the validation data\n",
        "\t\t\t-> The first value is this - for the training data\n",
        "\t\t-> The rest of the parameters we are using in this plotting function are for its appearance (the text not the axes, the presence of a legend and grid)\n",
        "\"\"\"\n",
        "\n",
        "def plot_loss(history):\n",
        "  plt.plot(history.history['loss'], label='loss')\n",
        "  plt.plot(history.history['val_loss'], label='val_loss')\n",
        "  #plt.ylim([0, 10])\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Error [MPG]')\n",
        "  plt.legend()\n",
        "  plt.grid(True)"
      ],
      "metadata": {
        "id": "jk7JvueMlCb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\t-> This cell calls the plotting function defined in the previous cell\n",
        "\t-> Why this plot is made the way that it is:\n",
        "\t\t-> The two series which this graph plots are the validation loss and loss functions for the model during its training\n",
        "\t\t-> When we train the model, we want to maximise its maximise its accuracy -> which means minimising its loss\n",
        "\t\t-> We take the entire dataset and split it into training data (80%) and test data (20%)\n",
        "\t\t-> `history` is taking the data about the value of the loss function when the model is being trained -> that is what is being plotted here\n",
        "\t\t-> An epoch refers to one time the model is trained on the entire dataset -> this model is trained on the same one 600 times\n",
        "\t\t-> We are doing this using the training dataset\n",
        "\t\t\t-> That dataset represents 80% of all of the data which we've imported into the project\n",
        "\t\t\t-> But for each epoch (time we train the model on that data), we are running the gradient descent algorithm on it twice\n",
        "\t\t\t\t-> We have taken the training data and divided it into validation and test data\n",
        "\t\t\t\t-> The validation data makes up 20% of the test data, which makes up 80% of the total dataset\n",
        "\t\t-> The reason we split the test data into test and validation data is because we want to know how consistent the results are when we train the model\n",
        "\t\t\t-> Which they are\n",
        "\t\t\t-> This indicates that the model is generalisable (and hasn't been overfit)\n",
        "\t\t\t-> Since we are using it to make predictions on other datasets\n",
        "\n",
        "\t-> What this shows:\n",
        "\t\t-> The training and validation loss curves are similar -> which means that the model can safely be generalised to other data\n",
        "\t\t-> Our model hasn't overfit the data\n",
        "\t\t-> Out loss curves have a huge decrease around 50 epochs -> and after this the loss functions don't dip as much\n",
        "\"\"\"\n",
        "\n",
        "plot_loss(history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "VLLPA3fslUn8",
        "outputId": "8ea98882-8825-4f2a-af73-40971d87ebf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Running Unit Tests for the Model in Python"
      ],
      "metadata": {
        "id": "hsIzKawGvtAd"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xe7RXH3N3CWU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "ed264082-63fc-4e82-fe22-f0d5cbb20661"
      },
      "source": [
        "#Running unit tests on our trained model using 20% of the data that was reserved for this\n",
        "#We are now testing the predictions of the model to see how accurate they are -> and plotting this\n",
        "\n",
        "\"\"\"\n",
        "\t-> This cell runs the unit tests for our project\n",
        "\t-> The model takes information about the patient demographics and uses the linear regression method to make predictions about the healthcare expenditures of that patient based on their demographics, which the model was previously trained on\n",
        "\t-> Considering that this is for a US healthcare system and the patients have to pay for their healthcare\n",
        "\t-> We initially imported the data into the notebook -> 80% of this data was used to train the model (this was randomly selected)\n",
        "\t-> The other 20% of the data was reserved for testing the trained model\n",
        "\t-> Considering that the previous cell trained this model - we are now using the remaining 20% of the data to perform these unit tests in this cell\n",
        "\t-> We know that the predictions that the model makes about the predicted healthcare expenditures of a patient aren't entirely inaccurate if they fall within an uncertainty of $3, 500\n",
        "\t\t-> This is what the code below is testing\n",
        "\t-> We are then plotting these predictions:\n",
        "\t\t-> We are doing this multiple times and plotting all of the predictions it makes for this on the graph below\n",
        "\t\t-> We are plotting these predictions in comparison to their actual values for the remaining 20% of the data reserved for this\n",
        "\t\t-> If the two match -> then they will fall on the line y = x\n",
        "\t\t-> This cell also returns a validation message for this, to confirm if our predictions are accurate enough in comparison to the project requirements\n",
        "\t-> The values we are comparing when we do this are the MAE and MSE of our predictions and of the test data which it hasn't seen before\n",
        "\t\t-> When we are doing this, we are also flattening the data into a 1D array\n",
        "\t\t-> The line y = x represents the perfect case, where our predicted values equal the values which we are trying to predict\n",
        "    -> Our model has successfully pass these tests in this case\n",
        "\"\"\"\n",
        "\n",
        "# Test model by checking how well the model generalizes using the test set.\n",
        "loss, mae, mse = model.evaluate(test_dataset, test_labels, verbose=2)\n",
        "\n",
        "print(\"Testing set Mean Abs Error: {:5.2f} expenses\".format(mae))\n",
        "\n",
        "if mae < 3500:\n",
        "  print(\"You passed the challenge. Great job!\")\n",
        "else:\n",
        "  print(\"The Mean Abs Error must be less than 3500. Keep trying.\")\n",
        "\n",
        "# Plot predictions.\n",
        "test_predictions = model.predict(test_dataset).flatten()\n",
        "\n",
        "a = plt.axes(aspect='equal')\n",
        "plt.scatter(test_labels, test_predictions)\n",
        "plt.xlabel('True values (expenses)')\n",
        "plt.ylabel('Predictions (expenses)')\n",
        "lims = [0, 50000]\n",
        "plt.xlim(lims)\n",
        "plt.ylim(lims)\n",
        "_ = plt.plot(lims,lims)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 - 0s - loss: 2148.6702 - mae: 2148.6699 - mse: 32152824.0000 - 37ms/epoch - 4ms/step\n",
            "Testing set Mean Abs Error: 2148.67 expenses\n",
            "You passed the challenge. Great job!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAASsAAAEKCAYAAABKVHMnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2dfZwcVZX3v79MJsmQ92DCy4RIxCwIj8jLKMGgAj4SQIUIIrC4RJcHdEVXRdGgrMFVPwRZEUFXCYKAorwIDllQQyAoKwIhYQIhSCQQkIxAgBAikJC38/xRtyc1na6e6slUd1fP+X4+/emqW7eqz0x6frn33HPOlZnhOI5T7wyotQGO4zhpcLFyHCcXuFg5jpMLXKwcx8kFLlaO4+QCFyvHcXJBpmIl6SlJSyQtlrQwtI2RNE/S4+F9dGiXpEskLZf0sKQDYs+ZHvo/Lml6rP3A8Pzl4V5l+fM4jlM7qjGyOszM9jOztnA+A7jTzCYBd4ZzgKOASeF1BvBjiMQNmAkcBLwLmFkQuNDn9Nh9R2b/4ziOUwtqMQ08Frg6HF8NTIu1X2MR9wGjJO0CTAXmmdlqM3sZmAccGa6NMLP7LIpsvSb2LMdxGoyBGT/fgNslGXCZmc0GdjKzZ8P154CdwnEr8Ezs3pWhrVz7yhLt2yDpDKLRGkOHDj1wr7322p6fyXGcErz2xiaeeul11j/7+ItmNravn5+1WB1iZp2SxgHzJD0Wv2hmFoQsU4JIzgZoa2uzhQsXZv2RjtOvWLBiNZ/42QIOHjmEu7582NNZfEam00Az6wzvq4DfEPmcng9TOML7qtC9E9gtdvv40FaufXyJdsdxqkhBqHYeOYTrTp+c2edkJlaShkoaXjgGjgAeAeYAhRW96cAt4XgOcGpYFZwMvBKmi3OBIySNDo71I4C54dpaSZPDKuCpsWc5jlMFioVq3IghmX1WltPAnYDfhGiCgcAvzez3kh4AbpB0GvA08LHQ/7fA0cBy4HXgkwBmtlrSt4AHQr//NLPV4fgzwFVAC/C78HIcpwpUU6gA1N9KxLjPynG2n3JCJWlRLFSpz/AIdsdxKqLaI6oCLlaO46SmVkIFLlaO46SklkIF2cdZOY6TU9o7Orlw7jL+vmYdOw4bxNr1mxg/uqUmQgUuVo7jlKC9o5Nzbl7Cuo2bAXjx1Q0ImH7w7jURKvBpoOM4Jbhw7rIuoSpgwOy7n6yNQbhYOY5Tgr+vWVdRezVwsXIcZxt2HDaoZPuuo1qqbMlWXKwcx+nGghWrWbt+E8WVLFuamzh76p41sQncwe44DltX/jrXrEPA2OGDOfOwtzL77if5+5p17DqqhbOn7sm0/UtWYaoKLlaO088pXvkzYO26jYxsaeaeGYfX1rgYPg10nH5OqZW/9Zu2cOHcZTWyqDQ+snKcfkY82HPXUS101uHKXylcrBynH1E85UsSKqjtyl8pXKwcpx9RaspXipbmJg7bayxTZs13B7vjONWn3NSudVRLlzAdttdYblrU2W0Eds7NSwBqJlguVo7Tj0jyUbWOaum28jdl1vxtRmDrNm7mwrnLXKwcx8mGuEN96KCmba6XCvb0dBvHcapKwaHeuWYdBry6IRotjWwZiIhGVOcf9/ZtRktJzvVaOt19ZOU4DUySQ33Y4GYemjk18b6zp+7ZbdUQPN3GcZwM6e10rjDSisdj+Wqg4ziZseOwQbz46oZt2tNM56bt31pTcSrGfVaO06DUa/WE3uJi5TgNSGFzh/GjWzjvmH1oHdVS1qGeB3wa6Dg5pzjX77gDWrniTyu67UIz/d27Z/qZ1fBnuVg5To45t30J1973Nwr7qneuWcel85czbvjgzHahKZVfWI3odp8GOk5Oae/o7CZUcQZIme1CUyocohDdniUuVo6TUy6cu6ykUAE8v3Z9Zp9bq+h2FyvHySnlxCHLSPNaRbe7WDlOTkkSB0GmoQlnT92TlubuOYbVCIdwB7vj5IhuScmDt01KFnDK5AmZOrprFd3uYuU4OaF4Fe7VN6L3EUMG8o/1m6qaElOL6HYXK8epc+LbZJVi+JBmHj4vOSm5UXCxcpw6png0VYp629ghK1ysHKeOSVMzPcnRXoso8yzJfDVQUpOkDkm3hvOJku6XtFzS9ZIGhfbB4Xx5uL577BnnhPZlkqbG2o8Mbcslzcj6Z3GcatLe0Vl29xlIXoUrLrpXiDJv7+jMyNrsqUbowueBv8TOLwC+b2ZvBV4GTgvtpwEvh/bvh35I2hs4CdgHOBL47yCATcCPgKOAvYGTQ1/HyT0FsSlHuaTkWkWZZ0mmYiVpPPBB4KfhXMDhwK9Dl6uBaeH42HBOuP7+0P9Y4Doze8PMVgDLgXeF13Ize9LMNgDXhb6Ok3vKTf9ampu4+MT9uGfG4YnTunqsob69ZO2zuhj4CjA8nO8IrDGzTeF8JVD4bbcCzwCY2SZJr4T+rcB9sWfG73mmqP2gUkZIOgM4A2DChAnb8eM4TnUoJyrx0VSSXyppF5t627i0EjIbWUn6ELDKzBZl9RlpMbPZZtZmZm1jx46ttTmO0yM7DhtUsr11VEs3oUryS9UqyjxLshxZTQGOkXQ0MAQYAfwAGCVpYBhdjQcKHr9OYDdgpaSBwEjgpVh7gfg9Se2Ok1viFT7jicrFYlPOL1XYA7CRVgMzEyszOwc4B0DSocCXzewUSTcCHyXyMU0Hbgm3zAnn94br883MJM0BfinpImBXYBKwgCizYJKkiUQidRLwz1n9PI6TFfGp3I7DBrF2/SbGj25h+sG7M/vuJxPFpie/VL3VUN9eahFn9VXgOknfBjqAK0L7FcDPJS0HVhOJD2a2VNINwKPAJuBMM9sMIOmzwFygCbjSzJZW9SdxnO2kOOjzxVc3IGD6wbsz/d27l63w2Yh+qXLILKkiTmPS1tZmCxcurLUZjgNE27SXEpzROzSzw6CBZadwpaLbW5qbal5jXdIiM2vr6+d6BLvj1IhyQZ8vv76Rl1/fCCSXDa60+kHeI9p9ZOU4NSBNzl8xraNauhznffF5WY3CshpZefE9x6kBaXL+itmegM5GiGj3aaDj1ICecv5KMbKlmSmz5vdqGtcIEe09ipWkAcA7iMIG1gGPmNmqrA1znEajp7pU5WgeIF7bsIk168r7sZJohJXDxGmgpD0kzSbKxZsFnAx8BrhD0n2SPhmEzHGcHohHm6elSeraRXnYkIFs3Nzdv1zJNK4RItrLjay+DfwY+JQVeeEljSMKwPwXtiYfO46TQJKPqklis1nJaPW483vijNtKPjftNK5WddP7kkSxMrOTy1xbRZSk7DhOCpJGVFvMeGrWB3sMK+iLaVzeI9rT+KxOAH5vZv+Q9B/A/sC3zezBzK1znByTxkdVEJuehOTsqXuWDD3I0zRue0njc/qPIFSHAO8nSov5cbZmOU6+SeOjqkRspu3fyvnHvZ3WUS1dfqxaR6pXmzShCwUp/yAw28xuC3l9juMkUM5HtcWsVz6jvE/jtpc0YtUp6TLgA8AFkgbjwaSOU5ZyPqoVsz5YZWsagzRi9TGi2uf/ZWZrJO0CnJ2tWY6TnnrLeVuwYvU2q3sFCj6qerM5D/QoVmb2uqRVwCHA40RlWh7P2jDHSUNxzlulwZJ9zYIVq/nEzxYwdvhg1q7byPpNW7quFXxU9WZzXuhxOidpJlENqnNCUzPwiyyNcpwC7R2dTJk1n4kzbmPKrPnbbCVVTzlvBaHaeeQQbv3cIcw6ft+SDvF6sjlPpJkGfoQoXOFBADP7u6Th5W9xnO0nzQikXnLe4kJ13emTGTdiSKJDvF5szhtpHOUbQgS7AUgamq1JjhORZgQysqW55L3VzHn73u3LOPGye3l9w2Zef2Mzf37ipbL9k2zLU55eLUgjVjeE1cBRkk4H7gAuz9Ysx+l5BNLe0clrGzZtc715gKoWLPm925dx6fzlXc7059au73Hn40bI06sFPYqVmf0X0aajNwF7At8ws0uzNsxxehqBXDh32TbJvQDDhgysiqN6wYrVXDp/+TbtPfmfPMCzd6RJtxlKtNPMPEl7AntKajazjdmb5/RnekoxSRp5rXk9+6/mghWr+fgV9yde78n/1N8DPHtDmmng3cBgSa3A74kqLVyVpVGOAz2PQGrl+yk407dsSS4J7v6nvifNaqBCrNVpwI/N7LuSFmdtmONA+RFILZJ746t+T77wWmI/9z/1PWlGVpJ0MHAKUCiq01Smv+NUhWr7forDE1oTRk+jWpp9ipcBaUZWnycKCP1N2HD0LcBd2ZrlOOmolu+nVBxV0sjuvGP2ydye/kiadJu7ifxWhfMngX/P0ijHqSdKCRU0RvXNPJFmNfCfgC8Du8f7m1nvNjBznByRJFQFfFWveqSZBt4I/AT4KVtrWzlOruhNlYOehMqpLmnEapOZeWVQJ7f0pspBGqHyMi/VJY1Y/Y+kzwC/Ad4oNJrZ6syscpw+pFyOYSlxSStUvSnz4gLXe9KI1fTwHi+4Z8Bb+t4cp5Gp1R9qJVUO0k79KhVAqL/aW3kjzWrgxGoY4jQ2tfxDTbuNVSU+qt6UeemNwDlbSVN8bwdJ54bdmZE0SdKHsjfNaSRqWXAuTZWDSp3pvUn18TpW20eaCPafARuAd4fzTqLdmh0nNbX8Q+0p0r03q369KfPiday2jzQ+qz3M7ERJJ0NXTXZlbJfTYPTFjsLbQ1I8VG/DE+IBoZ1r1tEkdRsplvos36h0+0hVKVRSC1srhe5BbFUwCUlDJC2Q9JCkpZK+GdonSrpf0nJJ10saFNoHh/Pl4frusWedE9qXSZoaaz8ytC2XNKOin9ypKvVYcG5746im7d/a9XNttqgCQ8EXV6r4ntex2j7SjKxmEpWG2U3StcAU4BMp7nsDONzMXpXUDPxJ0u+As4Dvm9l1kn4CnEa0w/NpwMtm9lZJJwEXACdK2hs4CdgH2BW4I0TVA/yIaD/DlcADkuaY2aOpfnKnqtRbakpfBXxW6jT3iPfek2Y1cJ6kB4HJgIDPm9mLKe4z4NVw2hxeBhwO/HNovxo4j0isjg3HEFUm/WGYbh4LXGdmbwArJC0H3hX6LQ+5iki6LvR1sapTKvlDzTLMoS8j091pXj3S7qz8PuD9wGHAe9I+XFJTqH21CpgHPAGsMbNC4eyVQOEb2Ao8AxCuvwLsGG8vuiepvZQdZ0haKGnhCy+8kNZ8p0YUwhw616zDKD+1qpS+TqFxp3n1SBO68N/Ap4ElwCPApyT9KM3DzWyzme0HjCcaDe21Hbb2GjObbWZtZtY2duzYWpjgVEBWYQ5Z5PrVoy+uUUnjszoceFuY1iHpamBpJR8Stp2/CziYaJecgWH0NJ4oFILwvhuwUtJAYCTwUqy9QPyepHYnx2QxtcoqKbnefHGNTBqxWg5MAJ4O57uFtrJIGgtsDELVQuQIv4CocN9HgeuIUnluCbfMCef3huvzzcwkzQF+KekiIgf7JGABkf9skqSJRCJ1Elt9YU6O6W2YQ5KfK+vqCe40rw5pxGo48BdJC4gc5O8CFgYRwcyOSbhvF+BqSU1E080bzOxWSY8C10n6NtABXBH6XwH8PDjQVxOJD6E66Q1EjvNNwJlmthlA0meBuURllq80s4pGfE590pt4pKR0nideeJUr/rTCy7w0AAqzu+QO0vvKXTezP/apRRnT1tZmCxcurLUZTg9Uuho4Zdb8kqMxARPHDnWhqiKSFplZW18/N83I6oXi2CVJh5rZH/raGMcpUOnUKsmfZeBC1SCk3T7+K4pokXQpcH7WhjlOJST5s3YeMcSFqkFII1YHETnY/ww8APydKIrdcapKe0cnU2bNZ+KM25gya363uKtSIQRDBg5gxlE1iZZxMiDNNHAjsA5oAYYAK8xsS6ZWObmhWgX1eqqHNW3/Vp544VV+OH85RjSimnHUXr5K10CkEasHiMIL3gm8CfiJpOPN7IRMLXPqnmoW1OspB2/BitVc8acV7kxvYNJMA08zs2+Y2UYze9bMjiWKiXL6OdUsqFcuUNR3oekfpBGrRZI+LukbAJImANmXd3Tqnmom8SY50HccNsiFqp+QRqz+myhN5uRw/g+i0ixOP6eaSbylHOiDmgawdv0mF6p+QqrVQDM7E1gPYGYvA4MytcrJBdVM4i0uXPemYYNAMH50iwtVPyHVamBImSkkMo8FfDXQqXoSb2HVr+CjcqHqX6QRq0uINjgdJ+k7REnG52ZqlZMbqp3E6870/kuaSqHXSlpEVHxPwDQz+0vmljlOoBDL1blmHQLGDh/sQtUPSRQrScPM7FUAM3sMeKxcH8fJguJYLgPWrtvIn594yQM++xnlRla3hJLEtwCLzOw1AElvISpv/DHgcqJ66U4/JCl6vS+j2kvFcq3ftMV3Me6HJIqVmb1f0tHAp4ApksYQpd4sA24DppvZc9Ux06k3kqLXFz69mpsWdfZZVHupsi/gGzL0R8r6rMzst8Bvq2SLkyOSotd/df8zXXvoxdvTjISKR2THHdCKCMvQRfiGDP2PNKuBjrMNSSObYqHqqX+BUiO1S+cvZ8SQgWzYtIX1m7ZGy/iGDP2TtFtxOU43kkY2TVJF/QuUGqkB7DBoILOO39d3MXZ8ZOX0jqQ66ccf2NrNZ1Vo72kklDTyen7tet+QwQFSiJWkPYCVZvaGpEOBfYFrzGxN1sY59UtP0esF31WTxPEHlhabePxUEu6bcgqkGVndBLRJeiswmyiU4ZfA0Vka5tQ/pUY87R2d3LSos8t3tdmMmxZ10vbmMcBWcRu1QzOvrt/Exi3JG5a4b8qJk0astpjZJkkfAS41s0sldWRtmJNPklYJz5uzlDc2bem69vLrG8s+p0ly35TTjbSJzCcTbUD64dDWnJ1JTp5J8j2tWVdenIrZYuZC5XQjzWrgJ4nqWX3HzFaEHZB/nq1ZTl7pKx+T+6qcYnoUKzN71Mz+3cx+Fc5XmNkF2Zvm5JGkGlejd0g/GHdflVOKNKuBU4DzgDeH/gLMzN6SrWlOXiiOPD/+wFbueuyFrvPD9hrLrQ89W/LeEUMGsnb9JpokNpvRmnFNLCe/pPFZXQF8EVgEbBu15/RrSkWe37Sos8s5Xny9wADBzA/vw/R3714Dq508ksZn9YqZ/c7MVpnZS4VX5pY5uaCnHW6SItPHDR/iQuVURJqR1V2SLgRuBt4oNJrZg5lZ5eSGpNW/QqBnuch0x6mENGJ1UHhvi7UZcHjfm+PkjV1HtZSMQBfRFDHpuq/2OZWSZjXwsBIvFyoHiFb/SqUuG9EU8LgDtnWU+2qf0xt6FCtJIyVdJGlheH1P0shqGOfUP9P2by1ZbwqiqeAVf1rBuOGD2TnUS2+Sunxa7R2d1TPUyT1pHOxXEm1s+rHwWgv8LEujnHzRmjClE7DzyCHc+rlDmHHUXrQ0N3XlDBYqiLpgOWlJI1Z7mNlMM3syvL4JeIyV00WpQFDovgtNT6uGjtMTacRqnaRDCichSNQLYDtdxHdLhmhENW74YG793CFd22UlrQp6LXUnLWnE6t+AH0l6StLTwA+BT/d0k6TdJN0l6VFJSyV9PrSPkTRP0uPhfXRol6RLJC2X9LCkA2LPmh76Py5peqz9QElLwj2XSAllKp3MmbZ/K98/cT92GNTExLFDuwkVJK/++aqgk5Y0q4GLzewdREX33m5m+5vZQymevQn4kpntDUwGzpS0NzADuNPMJgF3hnOAo4BJ4XUG8GOIxA2YSRRC8S5gZkHgQp/TY/cdmcIuJwN62ik5KWewUVYF2zs6mTJrPhNn3MaUWfPdF5cB5TY5/biZ/ULSWUXtAJjZReUebGbPAs+G439I+gvQChwLHBq6XQ38AfhqaL/GzAy4T9IoSbuEvvPMbHX4/HnAkZL+AIwws/tC+zXANOB3KX92p49Is6V7T5VF80zStmTQu+3HnNKUCwodGt6Hl7iWXN6xBJJ2B/YH7gd2CkIG8BywUzhuBZ6J3bYytJVrX1mivdTnn0E0WmPChAmVmO70QBqhKtCotdTLLR404s9bK8ptcnpZOLzDzO6JXwtO9lRIGkZUGvkLZrY27lYyM5NUkfD1BjObTVSSmba2tsw/r9GIV1UYtUMzZlExvQHAFmDgADH94N3LClUj44sH1SGNg/3SlG3bIKmZSKiuNbObQ/PzYXpHeF8V2juB3WK3jw9t5drHl2h3+pDCFKdzzTqMqBxxoepnYSe/TVuMWb97rN/6aXzxoDokipWkgyV9CRgr6azY6zxg26Cabe8XUXmZvxT5t+YQlUgmvN8Saz81rApOJqr28CwwFzhC0ujgWD8CmBuurZU0OXzWqbFnOX1EUtWEYvpzzFSjLx7UC+V8VoOAYaFP3G+1FvhoimdPAf4FWCJpcWj7GjALuEHSacDTRFHxEG1TfzSwHHidqJwyZrZa0reAB0K//yw424HPAFcBLUSOdXeu9zGVTGX667SnkRcP6glZwnbfXR2kN5vZ01WyJ3Pa2tps4cKFtTajbiiu8ln8RzZl1vyy+/rFaR3Vwj0zPMe9vyNpkZm19dyzMtKUiPmppBMKm5qGqdh1Zja1r41xqku5JXegawNS0fPyr097nKxJI1Zviu++bGYvSxqXoU1OlUi7x19cqEa2DESINes2et10p6qk2uRU0gQz+xtE00IqjLNy6pNK9/jbecQQ7vva+7M0yXESSSNWXwf+JOmPRDmq7yEEWDr5JqmKZxLPeSlip4akyQ38PXAAcD1wHXCgmc3N2jAne5KW3JPSwZs8T9ypIeXirPYK7wcAE4C/h9eEeEUEJ7/ES7uIaDXv/OPeTtIC8eYeVo4dJ0vKTQO/RFTR4HslrvmGEQ1CIV+vEMLwhesXJ/ZNqgjqONWgXG7g6eH9sOqZ49SCpI1I43hoglNrypWIOa7cjbFcPyfnJKXUNElsMfOIbKcuKDcN/HB4Hwe8G5gfzg8D/ky06anTACStCG4xY8WsD1bZmvqipwh/p3qUmwZ+EkDS7cDehRpUoVLCVVWxzsmE+B/gjsMGJfbr71UDvKhefZGmRMxusWJ5AM8TrQ46OaS9o5Ozb3yoq+TLi69uAGBAUVSC+6jKF9Vzqk+aoNA7Jc0FfhXOTwTuyM4kJ0vOm7OUjVu2DUHYYjB6h2bWvL7RpzsBL6pXX/QoVmb2WUkfAd4bmmab2W+yNcvpa9o7OjlvztLEVBqAHQYNpOMbR1TRqvomKcK/v0+Pa0WaaSDAg8BtZvZFYK6kUnXZnTqlMPUrJ1TgI4ZivKhefdGjWEk6Hfg1UKjJ3gq0Z2mU03e0d3TypRseKjn1K8ZHDN1JivDv79PjWpHGZ3Um0X599wOY2eNeIqb+STPti9M8QLkfMWQRZtCoO/LkkTRi9YaZbSjsSiNpIF4ipq5p7+jkrOsXd23o0BMSXHjCO3L9R+lhBo1PGp/VHyV9DWiR9AHgRuB/sjXL2R4qEarmJvH9j+2X+z9oDzNofNKMrL4K/D9gCfApoo0dfpqlUU7vOeXye1ML1egdmpn54X1yL1RQ/2EGHgm//ZQVK0lNwFIz2wu4vDomOb2lvaOTe55Y3WM/CVac31hpNPUcZuBT1L6h7DTQzDYDyyR5xHqd097RWba8S5xTDmq8f856DjPwKWrfkGYaOBpYKmkB8Fqh0cyOycwqpyLObV/CL+77W6q+H588gW9Pe3vGFlWfSvbuq/aUrN6nqHkhjVj9R+ZWOL2mvaMztVBdfGL+HenlSBNmUIspWT1PUfNEubLGQyR9ATgB2Au4x8z+WHhVzUKnLOfNWZqq38cnT2hooUpLLaZk9TxFzRPlRlZXAxuB/wWOAvYGPl8No5xkClOYSnalmbLHmIac+vWGWkzJfHv5vqGcWO1tZm8HkHQFsKA6JjlJpCk/XMyUPcZw7ekHZ2hVvqjVlMwj4befcmLVladhZpvk2zDVnKTyw6UQ8P0G91GlJe5QH7VDM80D1C1X0qdk+aCcWL1D0tpwLKII9rXh2MxsRObWOd1IO/VrbhIXfjTf6TN9RfFo9OXXN9LcJEa1NPPKOq/dlSfKlTVuSrrmVJeockK6GCrAhSpGqdHoxs3G0MEDWTzTa3fliTShC04Nae/o5IvXL06dOe6rft3pS4e6p8zUFherOqLUH8M3/2dpaqHyVb9t6SuHuqfM1J60lUKdjCn8MRQ2cij8Mbz8erp6VP1p1a+9o5Mps+YzccZtTJk1n/aOzsS+fRXj5CkztcdHVnVC0h9DGho1hQa2HW0ettdYblrUmXqE01cxTp4yU3syG1lJulLSKkmPxNrGSJon6fHwPjq0S9IlkpZLeljSAbF7pof+j0uaHms/UNKScM8lynlsRW+/9I0uVMWjzWvv+1vFI5xp+7dyz4zDWTHrg9wz43CA1COzAknTRk+ZqR5ZTgOvAo4sapsB3Glmk4A7wzlEEfKTwusM4McQiRswEziIqLTyzILAhT6nx+4r/qxc0ZsvfSMLFZQebSb579KKfdJ0uyfB8pSZ2pOZWJnZ3UBxcaVjidJ4CO/TYu3XWMR9wKiw8/NUYJ6ZrTazl4F5wJHh2ggzu8/MDLgm9qxcctheYyvqf/GJ+zW0UEFlo820Yt9b35NvHlF7qu2z2im2u/NzwE7huBV4JtZvZWgr176yRHtJJJ1BNGJjwoT6rOV0/YJ0lRMAJo0b2i/+SJJW8kT3EVYlI5zt8T15ykxtqdlqYBgRVWXjCTObbWZtZtY2dmxlI5hqcG77EjamrEU8adxQ5p11aKb21Aulpl4FoWoKLspKRzjue8ov1Rar58MUjvC+KrR3ArvF+o0PbeXax5dozx2VFs7rL0IF3ade0H1Etdmsa0RVyWjHfU/5pdpiNQcorOhNB26JtZ8aVgUnA6+E6eJc4AhJo4Nj/Qhgbri2VtLksAp4auxZueGUy+9NJVSif/ioSlFYyWsd1bLNMLw3cU7ue8ovmfmsJP0KOBR4k6SVRKt6s4AbJJ0GPA18LHT/LXA0sBx4HfgkgJmtlvQt4IHQ7z/NrOC0/wzRimML8Lvwyg2nXH5vus0d8OoJ0LdxTu57yieZiZWZnZxw6f0l+hrRzs+lnnMlcGWJ9oXA/9keG2vFue1LUgkVuFAV8NLAjvAt40sAAA2dSURBVKfbVJH2jk4mfe02r5neC9zX5Hi6TZWodEv3KXuMcaGK4aWBHRerKnH2jemFauAA9Zuk5EpwX1P/xqeBVeADF/0hdRzVAMF/nfCObA1ynBziI6uM+cBFf+DxVa/13BEYOqiJ73wkH8voXojOqTYuVhnR3tHJV379EBs2pwvSz1NScr0XonMhbUx8GpgB7R2dnHXD4oYUKqjvQnS9rarg1D8+ssqAL1yffnOHPIYnVKOueW9HR+WENG+/Z6c7LlZ9zL4zf5+6bx6FCrKva77w6dUVVQON4xU9GxefBvYh+878PWvfSFeKeEiTcilUkH1d81/d/0yvp5leVaFxcbHqA9o7Opk447bUQjVicBOPfefojK3Kjr5KBk4a7Wy20r6+NKMjj3RvXHwauJ1Uuq9fXqd+xfRFgGbSdLJJKilYaUZHHuneuLhYbSdfvenhivb18z+arZw9dc9uPiuIRkHHH9jazWdVaE87OvJI98bExaqXVFI0D2Cn4YNyn0LT1/FL5UZBbW8e46MjpxuyBP9Ao9LW1mYLFy7crmdUKlSNUIq4eOUOotGOF65zipG0yMza+vq5PrLqBZUIVd4CPpPoKX7Jo8adrHGxqpBKIqGn7DGmIYQKyscv1Xv6jdMYeOhCBRRW/tIwZY8xufdRxSkXv1TP6TdO4+BilZJz25fwhZQhChefuF9DCRWUj18qFX4AJLY7Tm9wsUpBpdtlNeLUpxAIOqqluattSHP09Sns4VdMUrvj9AYXqx6oVKgaxUeVxBubtlYRfPn1jZxz85LEiPOkdsfpDe5gL0MluX6NEplejiTfVFLEeavn4zl9iItVCdo7Oisq89KoU79iyuXyxXdLBs/Hc/oeF6siKhGqluYBnH/cvv1CqCA5lw8ioSoIVqvHWTkZ4GJVRCVC9ZdvHZWxNfXF2VP35OxfP8TGhAqoBaG6Z8bh1TXM6Re4WMU46DvzUvc9/7h9M7SkNHURJd6Dz9yL3DlZ4WJFJAJn37g49XZZtaieUA9R4hfOXcbGLeXVyovcOVnR70MXCj6qSoSqFgGf9RAl3tOoyZ3qTpb0e7GqZNWvlik0SUJRzSjxcqOm3lYLdZy09GuxOuXye1P3nTRuaE1TaJKEQlSWXL09JKXcXHziftwz4/CKhKq9o5Mps+YzccZtTJk137fKcnqk34rVKZffyz1PrE7Vd8oeY2pej+rsqXtSKnnFoGpTwb6qve57+zm9od862NMK1YjBTXWRlDxt/9bEKWs1V+D6omSw7+3n9IZ+O7JKw07DB/HwN4+stRldJKWv5G0Fzvf2c3qDi1UCLc0DuP/rH6i1Gd1olG2mfG8/pzf0S7FasKL8FHAAtQn67Im+8hnVmkYRXae65H7DCElHAj8AmoCfmtmscv3f9vb9TB+ZxbDBA1n1jze2uT6qpZnzjtkndwKQN+oiGt/JhKw2jMi1WElqAv4KfABYCTwAnGxmjybd07LrP9nBX5rNdadP5s9PvOR/MI7Tx7hYlUDSwcB5ZjY1nJ8DYGbnJ90zYrc9bfnShxg3YkiVrHSc/oVvxVWaVuCZ2PlK4KDiTpLOAM4Ip2/sNLLlkSrY1he8CXix1kZUQJ7szZOtkC97M3E+5l2sUmFms4HZAJIWZqH6WZAnWyFf9ubJVsiXvZK2bxfhBPK+GtgJ7BY7Hx/aHMdpMPIuVg8AkyRNlDQIOAmYU2ObHMfJgFxPA81sk6TPAnOJQheuNLOlPdw2O3vL+ow82Qr5sjdPtkK+7M3E1lyvBjqO03/I+zTQcZx+gouV4zi5oN+IlaQjJS2TtFzSjCp/9pWSVkl6JNY2RtI8SY+H99GhXZIuCXY+LOmA2D3TQ//HJU2PtR8oaUm45xKp9/u2S9pN0l2SHpW0VNLn69VeSUMkLZD0ULD1m6F9oqT7w/OvD4svSBoczpeH67vHnnVOaF8maWqsvU+/N5KaJHVIujUHtj4V/p0WF8IRavo9MLOGfxE5358A3gIMAh4C9q7i578XOAB4JNb2XWBGOJ4BXBCOjwZ+R1QEdDJwf2gfAzwZ3keH49Hh2oLQV+Heo7bD1l2AA8LxcKJ0pr3r0d5w/7Bw3AzcH557A3BSaP8J8G/h+DPAT8LxScD14Xjv8J0YDEwM35WmLL43wFnAL4Fbw3k92/oU8Kaitpp9D2ouJNV4AQcDc2Pn5wDnVNmG3ekuVsuAXcLxLsCycHwZUX5jt37AycBlsfbLQtsuwGOx9m79+sDuW4hyL+vaXmAH4EGiDIYXgYHF//ZEq8YHh+OBoZ+Kvw+Ffn39vSGKA7wTOBy4NXx2XdoanvEU24pVzb4H/WUaWCotp9YZyzuZ2bPh+Dlgp3CcZGu59pUl2rebMPXYn2jEUpf2hmnVYmAVMI9odLHGzDaVeH6XTeH6K8COvfgZesvFwFeAwl5KO9axrRBVzb5d0iJFKWtQw+9BruOsGgUzM0l1FUMiaRhwE/AFM1sbdyfUk71mthnYT9Io4DfAXjU2qSSSPgSsMrNFkg6ttT0pOcTMOiWNA+ZJeix+sdrfg/4ysqrHtJznJe0CEN5XhfYkW8u1jy/R3mskNRMJ1bVmdnO92wtgZmuAu4imQ6MkFf4jjj+/y6ZwfSTwUi9+ht4wBThG0lPAdURTwR/Uqa0AmFlneF9F9B/Bu6jl96CvfBv1/CIaQT5J5JAsOB/3qbINu9PdZ3Uh3R2V3w3HH6S7o3JBaB8DrCByUo4Ox2PCtWJH5dHbYaeAa4CLi9rrzl5gLDAqHLcA/wt8CLiR7k7rz4TjM+nutL4hHO9Dd6f1k0QO60y+N8ChbHWw16WtwFBgeOz4z8CRtfwe1FxIqvUiWq34K5FP4+tV/uxfAc8CG4nm5qcR+R/uBB4H7oj9Awr4UbBzCdAWe86/AsvD65Ox9jbgkXDPDwmZCb209RAiX8XDwOLwOroe7QX2BTqCrY8A3wjtbwl/CMuDGAwO7UPC+fJw/S2xZ3092LOM2KpUFt8buotVXdoa7HoovJYWnlfL74Gn2ziOkwv6i8/KcZyc42LlOE4ucLFyHCcXuFg5jpMLXKwcx8kFLlY5RtKOISN+saTnJHXGzgfVyKY/SMpsYwNJLZL+qGjPyFwj6Y5C1QKnZ1yscoyZvWRm+5nZfkQBhd8vnJvZhlhkdCPxr8DNFqXZ5J2fE1VXcFLgYtVgSLpK0k8k3Q98V9J5kr4cu/5IoTaSpI+HelCLJV1WPFoJ9ZFujJ0fGqvD9GNJCxWrI1XClldjxx+VdFU4HivpJkkPhNeU0P6+2MiwQ9LwEo89hagSROG5Z4dnPKyt9aw+IunOUGNpF0l/lbSzpE9IuiWM/h6XNDP2nJK/C0mvSvqOoppZ90naKbSfEH6XD0m6O7Q1SbowZs+nQvsuku4Oz35E0nvCx84hqjbgpMDFqjEZD7zbzM5K6iDpbcCJwJQwMttMJARx7gAOkjQ0nJ9IlNcGUURzG1EU+fsk7VuBfT8gGgW+Ezge+Glo/zJwZrDnPcC6IpsHEUVyPxXOjwAmEeWs7QccKOm9ZvYbooyBM4HLgZlm9lx4zLvCZ+4LnCCprYffxVDgPjN7B3A3cHpo/wYwNbQfE9pOA14JP9c7gdMlTQT+mah8y37AO4iyAjCzl4HBknas4HfXb2nEaYIDN6aYJr0fOBB4IFRUaGFrUirQtXvQ74EPS/o1Uf7XV8Llj4WyIQOJahPtTZT2kob/C+wdq+QwIlR5uAe4SNK1RFO9lUX3vQlYEzs/Irw6wvkwIvG6G/gcUSrHfWb2q9g988zsJQBJNxOlF20q87vYQFR7CmARUW0vgq1XSboBKCR7HwHsK+mj4XxksOcB4MqQIN5uZotj9qwCdiVKUnbK4GLVmLwWO95E9xH0kPAu4GozO6eHZ10HfBZYDSw0s3+E0cKXgXea2cthejekxL3xXK749QHAZDNbX9R/lqTbiHLc7pE01cziZUnWFT1HwPlmdlmJzx5PVDdqJ0kDzKxQQ6o4v8wo/7vYaFtz0jYT/mbM7NOSDiIS8EWSDgzP+ZyZzS1+iKT3hr5XSbrIzK4Jl4ZQNIJ0SuPTwMbnKaKSyiiqiz0xtN8JfFRRraJCbe03l7j/j+H+09k6BRxBJIivBB/OUQmf/bykt0kaAHwk1n470ciH8Nn7hfc9zGyJmV1ANBrpVpsqTJuaJBUEay7wr2FUhqRWSePCwsKVRP6gvxCVEi7wgfCztgDTiEZIaX8XXQRb7zezbwAvEJVBmQv8WxhBIemfJA0Nz3rezC4nmvIW/j0E7Ez0b+T0gI+sGp+bgFMlLSWq+PlXADN7VNK5RJUgBxBVhDgTeDp+s5ltDk71TwDTQ9tDkjqAx4iqQN6T8NkziKZQLwALiaZpAP8O/EjSw0TfwbuBTwNfkHQY0YhoKVHZkGJuJ5q63WFmtwd/071h+vYq8PHwrP81sz9JeohoendbuH9B+J2MB35hZoWNEHr8XRRxoaRJRKOpO4mqEzxMVArowSBELxAJ4qHA2ZI2BhtPDc84kGiaugmnR7zqgpMrwujwi2b2L7249xNEpUs+2+eG9QJJPwDmmNmdtbYlD/g00MkVZvYgcJcaICiUqBijC1VKfGTlOE4u8JGV4zi5wMXKcZxc4GLlOE4ucLFyHCcXuFg5jpML/j98Uj31u/dCOQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}